{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e167ba1c-9c1a-498f-9ba9-e6b543f9982a",
    "deepnote_cell_height": 133.953125,
    "deepnote_cell_type": "markdown",
    "id": "UXhdQ57tpNB4",
    "output_cleared": false
   },
   "source": [
    "# Notebook 3: Are GPT Detectors biased against non-native English Speakers?\n",
    "\n",
    "In 2022, OpenAI released a large language model called ChatGPT, which was able to mimic human writing to a high level of degree. With this new tool available, fear from educators, and other stakeholders, about AI-generated content lead to the rise of known GPT detectors to determine if texts were human or AI written. A study published in the journal of *Patterns* highlights a potential concern: [Are GPT detectors biased against non-native English speakers?](https://www.sciencedirect.com/science/article/pii/S2666389923001307) In this notebook, we will look into the data to determine if there is a biased component in GPT detectors. More information on the data set can be found [here](https://github.com/rfordatascience/tidytuesday/blob/main/data/2023/2023-07-18/readme.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Intial Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5f42976d-4b1a-442e-876c-00dc3cd465f8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 129.953125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 61530,
     "status": "ok",
     "timestamp": 1726680822286,
     "user": {
      "displayName": "Isaac Quintanilla-Salinas",
      "userId": "11102198638348214323"
     },
     "user_tz": 420
    },
    "execution_millis": 4092,
    "execution_start": 1610215175500,
    "id": "u07cykBypNB7",
    "outputId": "ae858620-1877-42dd-9a14-592a4cb6ef0d",
    "output_cleared": false,
    "source_hash": "9d70ea66",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This code will load the R packages we will use\n",
    "install.packages(c(\"csucistats\"),\n",
    "                 repos = c(\"https://inqs909.r-universe.dev\", \"https://cloud.r-project.org\"))\n",
    "library(csucistats)\n",
    "library(tidyverse)\n",
    "\n",
    "\n",
    "# Uncomment and run for categorical plots\n",
    "# csucistats::install_plots()\n",
    "# library(ggtricks)\n",
    "# library(ggmosaic)\n",
    "# library(waffle)\n",
    "\n",
    "# Uncomment and run for themes\n",
    "# csucistats::install_themes()\n",
    "# library(ThemePark)\n",
    "# library(ggthemes)\n",
    "\n",
    "\n",
    "detectors <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2023/2023-07-18/detectors.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2023/2023-07-18/detectors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "38f02a7c-f6ce-460b-b248-9dc8860444e9",
    "deepnote_cell_height": 69.96875,
    "deepnote_cell_type": "markdown",
    "id": "iyB5HdaMpNB8",
    "output_cleared": false
   },
   "source": [
    "## 1.0 - Thinking about the Question and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `detectors` data set contains 6,185 rows and 9 variables, where each row represent information about an essay. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 - Take a quick `glimpse()` on the data sets and identify variables that may be of interest for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 - Given the variables, what are some questions that you may want to explore from the data. Look at the source [page](https://github.com/rfordatascience/tidytuesday/blob/main/data/2023/2023-07-18/readme.md) for more information about the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 - Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 - Using the variable `kind`, what is the proportion of essays that were written by an \"AI\" model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 -  Using the `model` variable, what proportion of essays were written with \"GPT3\"? \"GPT4\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 - Using the `native` variable, how many essays were written by non-native English speakers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 - Using the `detector` variable, describe distribution of use with the different types of GPT detectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 - Effectiveness of GPT Detectors\n",
    "\n",
    "A GPT Detector is only good if it can differentiate between a human piece of work and an AI-generated one. In this section we will see how effective these GPT dettectors are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 - Generate a cross-tabulation table between the variables `model` and `.pred_class`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 - What percentage of essays were correctly classified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 - What percentage of essays were incorrectly classified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 -  Given that the paper was writen by a human, what is the percentage that it will be classified as human-created?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 - Given that the paper was written by GPT4, what is the proporiton that it will be classified as AI-created?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6 - Given that a paper was classified as written by a human, what is the proportion that it was actually written by a human?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7 - Given that a paper was classified as written by AI, what is the proportion that it was actually written by a AI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.8 - Look at question 3.6 and 3.7, what do you think these questions are really asking. Hint: These questions are much more powerful than they appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0  - Are GPT Detectors Biased?\n",
    "\n",
    "In this section, we will create a new data set called `detectors2`. This new data set will contain a new variable called `model2` which is similart to `model` from `detectors`, but it will reclassify \"Human\" as \"Native\" or \"Non-native\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 - Describe in words what you think the code is doing below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors2 <- detectors |> mutate(model2 = case_when(native == \"Yes\" & model == \"Human\" ~ \"Native\",\n",
    "                                                     native == \"No\" & model == \"Human\" ~ \"Non-native\",\n",
    "                                                     model == \"GPT3\" ~ \"GPT3\",\n",
    "                                                     model == \"GPT4\" ~ \"GPT4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 - Obtain the continguency table for both variables `model` and `model2` from the `detectors2` data set. Does the variable `model2` look like it was created correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 - Create a cross-tabs table between `model2` and `.pred_class`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 - Given that a native student wrote the paper, what is the proportion of it being classified as AI written?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 - Given that a non-native student wrote the paper, what is the proportion of it being classified as AI written?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.6 - Compare the two proportions between 4.4 and 4.5. What conclusions can you draw from the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.7 - In 4.4 and 4.5, what method did you use to calculate the answer? Row or column proportion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.8 - Based on your answer in 4.7, why would the other method (row or column, opposite of what you wrote from 4.7), will not work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Submit Notebook\n",
    "\n",
    "Submit your notebook to canvas."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "nbsimplegrader",
  "colab": {
   "provenance": [
    {
     "file_id": "1ZeqeudDN8EUa7erB-iFvvREmLIV8MqVN",
     "timestamp": 1726470223770
    }
   ]
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "66e4a228-7f5c-4a5f-adf2-ef5bdb093f61",
  "kernelspec": {
   "display_name": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "r"
  },
  "nbsimplegrader": {
   "publish_config": {
    "classes": [],
    "options": [],
    "tools": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
