{
  "hash": "d504b15dfdac98108a5d0954d1ebc837",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Sampling Distribution\"\ndate: 4/1/25\nformat:\n  revealjs:\n    width: 1200\n    sc-sb-title: true\n    footer: <https://m201.inqs.info/lectures/9>\n    df-print: paged\n    scrollable: true\n    theme: [default, styles.scss]\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    code-fold: true\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n  - reveal-auto-agenda\n\neditor: source\n---\n\n\n\n\n\n# Sampling Distribution\n\n## Sampling Distribution\n\nSampling Distribution is the idea that the statistics that you generate (slopes and intercepts) have their own data generation process.\n\n::: fragment\nIn other words, the numerical values you obtain from the `lm` and `glm` function can be different if we got a different data set.\n:::\n\n::: fragment\nSome values will be more common than others. Because of this, they have their own data generating process, like the outcome of interest has it's own data generating process.\n:::\n\n## Sampling Distributions\n\n- Distribution of a statistic over repeated samples\n\n- Different Samples yield different statistics\n\n::: notes\nIf we took many samples, the statistics (like means) would vary. Their distribution helps us quantify uncertainty.\n:::\n\n## Standard Error\n\nThe Standard Error (SE) is the standard deviation of a statistic itself.\n\n::: fragment\nSE tells us how much a statistic varies from sample to sample. Smaller SE = more precision.\n:::\n\n\n\n## Modelling the Data\n\n$$\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\n$$ \n\n- $Y_i$: Outcome data \n- $X_i$: Predictor data \n- $\\beta_0, \\beta_1$: parameters \n- $\\varepsilon_i$: error term\n\n## Error Term\n\n$$\n\\varepsilon_i \\sim DGP\n$$\n\n::: notes\n-   The error terms forces the outcome variable to be different from the mathematical model.\n-   The numbers being generated are random and cannot be predicted.\n:::\n\n## Randomness Effect\n\nThe randomness effect is a sampling phenomenom where you will get different samples everytime you sample a population.\n\n::: fragment\n\nGetting different samples means you will get different statistics.\n\n:::\n\n\n::: fragment\n\nThese statistics will have a distribution on their own.\n\n::: \n\n## Randomness Effect 1\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 4 + 5 * x + rnorm(1000)\nbb <- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta}_1 = %g$)', bb)),\n           parse = TRUE,\n           size = 8) \n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n## Randomness Effect 2\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 4 + 5 * x + rnorm(1000)\nbb <- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta}_1 = %g$)', bb)),\n           parse = TRUE,\n           size = 8) \n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n## Randomness Effect 3\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 4 + 5 * x + rnorm(1000)\nbb <- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta}_1 = %g$)', bb)),\n           parse = TRUE,\n           size = 8) \n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n## Randomness Effect 4\n\n\n\n::: {.cell ecode-fold='true'}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 4 + 5 * x + rnorm(1000)\nbb <- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta}_1 = %g$)', bb)),\n           parse = TRUE,\n           size = 8) \n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n## Randomness Effect 5\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 4 + 5 * x + rnorm(1000)\nbb <- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta}_1 = %g$)', bb)),\n           parse = TRUE,\n           size = 8) \n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n\n\n# Simulating Unicorns\n\n## Simulating Unicorns\n\nTo better understand the variation in statistics, let's simulate a data set of unicorn characteristics to visualize and understand the variation.\n\n::: fragment\nWe will simulate a data set using the `unicorns` function and only need to specify how many unicorns you want to simulate.\n:::\n\n## Simulating Unicorn Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nunicorns(10)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Unicorn_ID\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Age\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Gender\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Color\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Type_of_Unicorn\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Type_of_Horn\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Horn_Length\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Horn_Strength\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Weight\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Health_Score\"],\"name\":[10],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Personality_Score\"],\"name\":[11],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Magical_Score\"],\"name\":[12],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Elusiveness_Score\"],\"name\":[13],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Gentleness_Score\"],\"name\":[14],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Nature_Score\"],\"name\":[15],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"19\",\"3\":\"Female\",\"4\":\"Pink\",\"5\":\"Ember\",\"6\":\"Aquamarine\",\"7\":\"4.751276\",\"8\":\"29.47682\",\"9\":\"138.9507\",\"10\":\"7\",\"11\":\"0.3255473\",\"12\":\"11218.61\",\"13\":\"35.28424\",\"14\":\"-21.547061\",\"15\":\"974.5445\"},{\"1\":\"2\",\"2\":\"4\",\"3\":\"Non-binary\",\"4\":\"White\",\"5\":\"Ember\",\"6\":\"Opal\",\"7\":\"5.407963\",\"8\":\"29.51953\",\"9\":\"149.9041\",\"10\":\"6\",\"11\":\"1.4486770\",\"12\":\"10820.29\",\"13\":\"33.87972\",\"14\":\"47.316968\",\"15\":\"924.6174\"},{\"1\":\"3\",\"2\":\"20\",\"3\":\"Non-binary\",\"4\":\"Pink\",\"5\":\"Ember\",\"6\":\"Aquamarine\",\"7\":\"5.231032\",\"8\":\"26.26181\",\"9\":\"135.0586\",\"10\":\"4\",\"11\":\"0.1647767\",\"12\":\"11257.54\",\"13\":\"36.78692\",\"14\":\"32.368780\",\"15\":\"979.4081\"},{\"1\":\"4\",\"2\":\"16\",\"3\":\"Male\",\"4\":\"Black\",\"5\":\"Jewel\",\"6\":\"Aquamarine\",\"7\":\"5.526068\",\"8\":\"24.38795\",\"9\":\"128.6481\",\"10\":\"4\",\"11\":\"1.0093263\",\"12\":\"11144.18\",\"13\":\"32.63975\",\"14\":\"-21.158005\",\"15\":\"965.4645\"},{\"1\":\"5\",\"2\":\"13\",\"3\":\"Female\",\"4\":\"Black\",\"5\":\"Rainbow\",\"6\":\"Aquamarine\",\"7\":\"4.885145\",\"8\":\"26.32881\",\"9\":\"145.8056\",\"10\":\"9\",\"11\":\"0.2891628\",\"12\":\"11020.37\",\"13\":\"30.19325\",\"14\":\"9.310035\",\"15\":\"949.9397\"},{\"1\":\"6\",\"2\":\"12\",\"3\":\"Male\",\"4\":\"Black\",\"5\":\"Ember\",\"6\":\"Opal\",\"7\":\"5.414021\",\"8\":\"27.17348\",\"9\":\"168.2732\",\"10\":\"1\",\"11\":\"1.5175543\",\"12\":\"11081.23\",\"13\":\"34.01854\",\"14\":\"29.013749\",\"15\":\"957.1210\"},{\"1\":\"7\",\"2\":\"17\",\"3\":\"Male\",\"4\":\"Gold\",\"5\":\"Ruvas\",\"6\":\"Aquamarine\",\"7\":\"5.535770\",\"8\":\"34.74184\",\"9\":\"155.3580\",\"10\":\"4\",\"11\":\"1.9694461\",\"12\":\"11145.77\",\"13\":\"35.89912\",\"14\":\"17.999650\",\"15\":\"965.4777\"},{\"1\":\"8\",\"2\":\"11\",\"3\":\"Female\",\"4\":\"Gray\",\"5\":\"Rainbow\",\"6\":\"Opal\",\"7\":\"4.869330\",\"8\":\"27.31360\",\"9\":\"132.9348\",\"10\":\"3\",\"11\":\"0.1118596\",\"12\":\"10994.20\",\"13\":\"33.86673\",\"14\":\"-17.605096\",\"15\":\"946.4485\"},{\"1\":\"9\",\"2\":\"13\",\"3\":\"Non-binary\",\"4\":\"Pink\",\"5\":\"Jewel\",\"6\":\"Opal\",\"7\":\"4.828354\",\"8\":\"28.87200\",\"9\":\"135.0954\",\"10\":\"10\",\"11\":\"0.2239951\",\"12\":\"11117.59\",\"13\":\"40.94997\",\"14\":\"12.371346\",\"15\":\"961.6564\"},{\"1\":\"10\",\"2\":\"9\",\"3\":\"Male\",\"4\":\"Silver\",\"5\":\"Ember\",\"6\":\"Aquamarine\",\"7\":\"5.238384\",\"8\":\"29.92003\",\"9\":\"155.2000\",\"10\":\"3\",\"11\":\"0.9154329\",\"12\":\"10933.74\",\"13\":\"37.57341\",\"14\":\"17.124310\",\"15\":\"938.9506\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n## Unicorn Data Variables\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nnames(unicorns(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  [1] \"Unicorn_ID\"        \"Age\"               \"Gender\"           \n#>  [4] \"Color\"             \"Type_of_Unicorn\"   \"Type_of_Horn\"     \n#>  [7] \"Horn_Length\"       \"Horn_Strength\"     \"Weight\"           \n#> [10] \"Health_Score\"      \"Personality_Score\" \"Magical_Score\"    \n#> [13] \"Elusiveness_Score\" \"Gentleness_Score\"  \"Nature_Score\"\n```\n\n\n:::\n:::\n\n\n\nWe will only look at `Magical_Score` and `Nature_Score`.\n\n## Magical and Nature Score\n\n$$\nMagical =  3423 + 8 \\times Nature + \\varepsilon\n$$ \n\n$$\n\\varepsilon \\sim N(0, 3.24)\n$$\n\n## Simulating $N(0, 3.24)$\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrnorm(1, 0, sqrt(3.24))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.6668308\n```\n\n\n:::\n:::\n\n\n\n## Collecting\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nunicorns(10) |> select(Nature_Score, Magical_Score)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Nature_Score\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Magical_Score\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"926.6881\",\"2\":\"10836.42\"},{\"1\":\"971.0379\",\"2\":\"11192.27\"},{\"1\":\"949.8103\",\"2\":\"11019.73\"},{\"1\":\"929.7874\",\"2\":\"10860.47\"},{\"1\":\"930.6215\",\"2\":\"10869.17\"},{\"1\":\"962.6124\",\"2\":\"11124.08\"},{\"1\":\"910.2146\",\"2\":\"10704.58\"},{\"1\":\"947.2785\",\"2\":\"11004.69\"},{\"1\":\"957.6573\",\"2\":\"11082.95\"},{\"1\":\"917.9370\",\"2\":\"10768.06\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n## DGP of Magical Score 1\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(unicorns(500), aes(Magical_Score)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n## DGP of Magical Score 2\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(unicorns(500), aes(Magical_Score)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\n## Estimating $\\beta_1$ via `lm`\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nu1 <- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = Magical_Score ~ Nature_Score, data = u1)\n#> \n#> Coefficients:\n#>  (Intercept)  Nature_Score  \n#>     3429.469         7.993\n```\n\n\n:::\n:::\n\n\n\n## Collecting a new sample\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nu2 <- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = Magical_Score ~ Nature_Score, data = u2)\n#> \n#> Coefficients:\n#>  (Intercept)  Nature_Score  \n#>     3426.732         7.996\n```\n\n\n:::\n:::\n\n\n\n## Collecting a new sample\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nu3 <- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = Magical_Score ~ Nature_Score, data = u3)\n#> \n#> Coefficients:\n#>  (Intercept)  Nature_Score  \n#>     3416.679         8.007\n```\n\n\n:::\n:::\n\n\n\n## Collecting a new sample\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nu4 <- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = Magical_Score ~ Nature_Score, data = u4)\n#> \n#> Coefficients:\n#>  (Intercept)  Nature_Score  \n#>     3425.070         7.998\n```\n\n\n:::\n:::\n\n\n\n## Collecting 1000 Samples\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nbetas <- replicate(1000,\n                   b(Magical_Score ~ Nature_Score, 1, unicorns(500)))\n\nbetas\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>    [1] 7.989652 8.003543 8.010756 8.004096 8.003637 7.995764 8.008007 8.003741\n#>    [9] 7.998498 7.995851 7.994916 7.995579 7.998023 7.997654 7.996468 8.006221\n#>   [17] 7.999203 8.000262 8.001413 8.004086 7.996831 7.999385 8.000844 7.997246\n#>   [25] 8.002398 8.001573 7.993490 8.000766 8.005181 7.995817 7.999482 8.009844\n#>   [33] 8.002791 7.996981 8.005832 7.996770 7.994621 7.998609 7.999801 7.994373\n#>   [41] 7.994825 8.000310 7.998185 8.003546 8.006293 8.001820 8.001500 8.002402\n#>   [49] 7.997946 7.994859 8.003883 7.995716 7.996475 8.000716 8.002763 8.000890\n#>   [57] 8.000422 7.998220 8.005701 8.002509 7.996645 8.003105 8.001148 7.994402\n#>   [65] 8.003627 7.999611 7.997665 8.002103 8.006861 7.992588 7.995752 7.998530\n#>   [73] 8.001161 8.007514 7.992915 8.005059 7.993574 8.001697 7.995825 7.995347\n#>   [81] 7.998011 8.005677 7.994656 8.002967 7.999838 8.000753 7.993252 8.001412\n#>   [89] 8.001687 7.996933 8.005002 7.993976 7.998048 7.996915 8.000532 8.001506\n#>   [97] 7.998693 8.002472 8.005043 7.998213 8.002895 8.003489 8.001791 8.003883\n#>  [105] 8.000411 8.002987 8.002276 8.007299 8.007060 8.002389 8.003743 7.997831\n#>  [113] 7.999875 8.002880 8.003886 8.010486 7.992447 7.999117 7.996540 7.999361\n#>  [121] 8.005968 7.994937 8.002908 7.993921 8.001648 7.996185 8.005757 7.994207\n#>  [129] 8.001568 8.001423 8.003807 7.994776 7.996703 7.987148 7.996820 8.009132\n#>  [137] 7.999123 7.999013 7.998500 7.998509 7.996675 7.989941 7.999783 8.000284\n#>  [145] 8.005647 8.004133 8.002833 7.998480 8.005748 7.996539 8.002886 7.997866\n#>  [153] 8.001139 8.000701 7.997206 8.006379 7.996508 7.994486 7.996547 7.996178\n#>  [161] 7.998200 8.004176 8.008583 8.001866 7.999772 8.005825 8.002049 8.003305\n#>  [169] 8.002638 7.995641 7.998380 7.998667 7.999528 8.002548 8.003065 7.994341\n#>  [177] 7.993038 8.009883 8.010199 8.002232 8.001966 8.001887 7.998058 7.997038\n#>  [185] 8.001211 7.998964 8.000450 7.992166 8.007127 8.001260 7.998222 7.999168\n#>  [193] 7.995825 7.995093 7.999505 7.995287 8.002208 8.005368 8.000947 7.998061\n#>  [201] 7.999756 8.005696 8.009132 7.998788 7.991405 8.004019 8.003004 7.997461\n#>  [209] 8.005465 7.997526 7.991154 7.994112 7.997901 8.005502 7.994908 7.997413\n#>  [217] 8.003193 8.001444 7.997942 8.002712 7.995344 7.997204 8.007023 8.003666\n#>  [225] 8.004398 7.995114 7.997810 7.991911 8.003532 7.998854 8.001721 8.000935\n#>  [233] 8.000608 8.000671 8.000876 8.002365 7.990742 7.998247 7.998157 7.998503\n#>  [241] 7.996769 7.999546 8.001954 7.999751 8.001486 7.999868 8.007291 7.997888\n#>  [249] 8.007933 7.998791 7.996166 7.994613 7.998918 7.991609 8.004515 8.001756\n#>  [257] 8.001238 7.995016 7.992274 8.002633 8.001283 8.000292 7.999214 8.003319\n#>  [265] 8.007440 8.001289 7.995495 7.994580 8.003605 8.000631 7.996838 8.002023\n#>  [273] 7.997004 7.995739 8.000549 8.004615 7.997560 8.006623 8.001812 8.007178\n#>  [281] 8.005892 7.998664 8.002293 8.003187 7.996699 8.001467 7.999929 7.995104\n#>  [289] 8.000036 7.992741 7.997304 7.997416 7.995065 7.998575 7.997808 7.995947\n#>  [297] 8.010585 7.999841 8.000443 7.997778 8.003767 7.996731 8.001069 7.995047\n#>  [305] 7.991304 8.005394 7.994117 8.000127 8.004291 8.001174 7.997438 7.998274\n#>  [313] 7.998911 7.998133 8.002353 8.002937 7.996111 7.998552 7.997273 8.004969\n#>  [321] 7.997765 8.005095 7.998248 7.992799 7.997859 7.997689 8.004623 7.997985\n#>  [329] 8.002248 7.993281 8.001653 8.006813 7.994040 7.992532 8.001183 7.995635\n#>  [337] 7.999671 8.000342 8.006109 7.998105 8.002997 8.004924 8.004759 7.999845\n#>  [345] 8.004146 8.003766 8.002071 8.002880 7.998035 8.000041 7.998340 8.002942\n#>  [353] 8.000761 8.006633 8.002660 8.001559 8.004708 7.996762 8.002020 7.997341\n#>  [361] 8.003195 8.000032 7.996191 7.998402 8.000951 8.001706 7.998786 8.001781\n#>  [369] 7.993194 8.003399 8.001184 7.995557 8.004886 7.993653 8.002885 8.000531\n#>  [377] 7.992916 8.000647 8.002392 7.993792 8.002170 7.996120 8.006104 7.999615\n#>  [385] 7.997024 8.000717 7.992920 8.003228 7.998167 8.002339 8.010186 7.996352\n#>  [393] 7.994161 7.991416 7.994571 8.000426 7.994403 7.998372 7.997737 8.004192\n#>  [401] 7.997368 8.001108 8.001707 8.004758 8.003838 7.999512 7.995988 8.002316\n#>  [409] 8.002513 8.001977 8.003984 7.997166 8.008470 8.001684 8.001339 7.998589\n#>  [417] 8.008601 7.997852 7.993673 8.000003 8.003412 8.004974 8.000005 7.998649\n#>  [425] 8.001631 7.999489 8.005032 8.004107 7.993897 7.992037 8.003970 8.000999\n#>  [433] 8.000681 8.004095 8.001317 7.995614 7.998956 7.995575 8.002991 7.992180\n#>  [441] 8.000611 8.007390 7.998230 7.998990 7.994982 7.992899 8.000375 8.001919\n#>  [449] 7.996284 8.000373 7.993086 7.999313 7.999841 8.001515 8.004923 7.999048\n#>  [457] 8.003503 8.000545 7.999176 7.996339 7.998584 8.003616 7.994414 8.002359\n#>  [465] 7.999307 7.991806 7.998453 8.000026 8.004717 7.998781 8.002359 7.993711\n#>  [473] 8.001582 7.998844 7.999668 7.998582 7.995277 7.997560 8.001448 7.995567\n#>  [481] 8.005947 8.004865 7.997810 7.999363 8.005472 8.003414 7.999019 7.996107\n#>  [489] 8.008131 8.005367 8.001245 8.006328 8.000316 8.008436 8.000638 8.001214\n#>  [497] 7.991253 8.002400 8.000461 7.992003 7.995946 8.008431 8.007672 8.002954\n#>  [505] 8.002020 7.993284 7.997538 7.998892 8.000779 7.997553 8.001685 7.998977\n#>  [513] 7.999162 8.003482 7.999038 7.992662 8.001285 7.998621 7.998963 7.997455\n#>  [521] 7.997778 7.999866 8.001575 8.003871 8.005755 7.994094 8.003238 7.996410\n#>  [529] 7.999401 7.997130 8.001914 7.995981 8.002090 7.992232 8.005685 8.006994\n#>  [537] 8.002715 7.995652 8.000398 8.000904 7.995904 8.003358 7.999840 7.999074\n#>  [545] 7.995341 8.002593 8.000615 7.994566 8.001878 8.000877 7.997935 7.991918\n#>  [553] 7.995716 7.999317 8.001583 7.998612 8.005617 7.995743 8.002417 8.002298\n#>  [561] 7.995177 7.999008 8.001488 7.999107 7.998112 7.998480 7.999075 7.997953\n#>  [569] 7.993171 7.996893 8.001334 7.998299 8.008644 7.996646 8.005910 7.999206\n#>  [577] 7.996915 8.001000 7.999414 8.006885 7.998904 7.995838 8.003363 7.999886\n#>  [585] 8.002329 8.003936 7.995102 8.003027 8.007189 8.002634 8.000988 8.001524\n#>  [593] 8.003687 8.004595 7.997612 7.996352 8.000383 7.996768 8.002102 7.999952\n#>  [601] 8.001412 7.996220 7.998847 7.996335 8.001858 8.001112 8.005859 8.004721\n#>  [609] 7.997830 8.002548 8.000956 7.997212 8.007979 8.003631 8.000852 7.999064\n#>  [617] 8.000439 8.003915 7.998307 8.000596 7.996950 8.000390 8.001901 7.995229\n#>  [625] 7.994213 8.004471 8.002236 8.005324 7.999015 8.002489 8.002233 7.996420\n#>  [633] 7.997591 8.003554 7.998618 7.998396 8.003921 8.003077 8.004778 8.001370\n#>  [641] 7.998348 7.994761 7.994253 7.998578 8.004710 8.003006 7.998111 8.000701\n#>  [649] 8.009396 7.996706 7.997097 7.998816 7.997630 7.999002 8.010348 8.004708\n#>  [657] 8.001174 8.000846 7.995132 7.998672 8.000781 7.995573 8.005054 8.005086\n#>  [665] 8.001149 8.007867 7.996597 7.992586 7.997617 7.995077 7.996615 8.000034\n#>  [673] 7.996159 7.998699 7.997149 8.002913 8.000842 7.999513 7.994228 7.998189\n#>  [681] 7.993702 7.998700 8.006393 8.008688 8.002172 8.002705 7.995801 8.012540\n#>  [689] 7.999145 8.001269 7.997866 7.995397 8.004674 7.997549 8.005765 8.002800\n#>  [697] 7.998303 8.002591 8.001439 7.999217 8.003429 7.996139 7.994125 7.996828\n#>  [705] 8.003091 7.999405 7.999452 7.997061 7.999835 7.995009 7.995335 7.997909\n#>  [713] 8.001858 7.998916 7.995379 7.999677 7.990692 8.003055 7.998908 7.999948\n#>  [721] 7.998187 8.000902 8.000607 7.999348 8.003564 8.003132 8.008043 7.991945\n#>  [729] 7.998711 7.997817 8.007538 7.993661 7.998732 8.001161 7.999400 7.998264\n#>  [737] 8.001762 8.010270 7.998578 8.000237 8.005641 8.003057 8.000632 8.003353\n#>  [745] 8.007764 8.009525 7.998714 7.996332 7.999522 8.002833 8.001737 8.003688\n#>  [753] 8.004344 7.999250 7.998596 7.994363 8.000115 8.006207 7.998939 8.002617\n#>  [761] 8.005347 8.005226 8.003653 8.001027 7.995095 7.996901 8.008107 8.003738\n#>  [769] 7.987346 7.999347 7.998851 8.006410 7.997691 8.002050 8.000813 8.001916\n#>  [777] 8.006004 7.999818 8.009820 7.999928 8.001859 7.999679 7.992400 7.994971\n#>  [785] 7.999723 8.001626 8.004030 8.003742 7.994280 7.997065 8.000266 8.010044\n#>  [793] 7.996539 8.004229 7.997082 7.989482 8.008081 7.997547 8.002588 8.001464\n#>  [801] 8.000625 7.989536 7.999608 7.999308 8.001177 8.007748 7.989830 7.995473\n#>  [809] 8.002836 8.001386 8.000426 7.997637 7.995036 8.008162 7.999509 8.000769\n#>  [817] 7.999356 8.003516 7.998511 8.000789 8.000624 8.000320 8.001683 7.998182\n#>  [825] 8.007809 7.997308 8.000188 7.997567 7.999694 8.001335 8.001374 7.998388\n#>  [833] 8.001381 8.000637 7.997067 8.001197 7.994088 8.007188 8.001241 8.001211\n#>  [841] 8.002961 7.996181 8.001441 8.000390 8.000971 8.005919 8.005505 8.000183\n#>  [849] 8.001004 7.993623 7.990650 8.001035 8.009312 8.003463 8.003055 7.998201\n#>  [857] 8.000786 8.005251 7.996670 7.996103 7.997970 7.997271 8.001018 7.996941\n#>  [865] 8.000225 7.988694 8.006539 8.001058 8.003879 7.994085 7.997874 7.998349\n#>  [873] 7.998732 7.994300 7.998936 8.002208 8.000654 8.001785 7.996413 8.003711\n#>  [881] 8.003125 7.995180 8.001347 8.007976 8.002772 7.998218 8.006289 7.995362\n#>  [889] 8.002782 8.000462 8.009278 7.997534 8.003989 8.002608 8.002546 7.996312\n#>  [897] 8.002350 8.003735 7.999909 7.999885 8.005778 8.003947 7.998705 8.004398\n#>  [905] 8.001451 8.001953 8.004642 8.008513 8.004315 8.000302 8.001632 7.998120\n#>  [913] 8.008820 8.000961 8.002181 7.993452 7.999881 7.997160 7.994504 8.000999\n#>  [921] 8.003838 7.998541 8.001189 8.003449 7.999161 7.997011 7.997692 7.998657\n#>  [929] 8.008625 7.999495 8.008789 8.001824 7.997664 7.991622 8.005850 7.999545\n#>  [937] 8.005850 7.999533 8.000754 7.997326 8.005579 7.996116 7.996887 8.008711\n#>  [945] 7.995075 8.000057 7.999504 8.002033 7.992346 8.003777 8.001041 8.001116\n#>  [953] 8.002477 8.007987 8.001708 7.997783 7.992442 7.996328 8.005871 7.996783\n#>  [961] 7.996932 8.001290 8.002035 7.997210 8.007660 8.008281 7.997974 7.997753\n#>  [969] 7.999255 7.996979 7.998354 7.999961 7.993001 8.003507 8.003284 8.002771\n#>  [977] 7.997877 7.994868 8.001186 7.998679 7.998448 7.997703 8.000902 8.002123\n#>  [985] 7.996185 7.996868 8.002069 7.997819 7.998858 7.992852 7.992708 8.004082\n#>  [993] 7.999398 8.005436 7.996936 8.009974 7.996182 7.992881 8.000642 7.997912\n```\n\n\n:::\n:::\n\n\n\n## Distributions of $\\hat \\beta_1$\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(data.frame(x = betas), aes(x = x)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n\n# Central Limit Theorem\n\n## Central Limit Theorem\n\nThe Central Limit Theorem (CLT) is a fundamental concept in probability and statistics. It states that the distribution of the sum (or average) of a large number of independent, identically distributed (i.i.d.) random variables will be approximately normal, regardless of the underlying distribution of those individual variables.\n\n\n## Formal Statement of the CLT\n\n- Let $X_1$, $X_2$, ..., $X_n$ be a sequence of i.i.d. random variables with mean $\\mu$ and standard deviation $\\sigma$.\n- Let $\\bar X$ be the sample mean of these variables.\n- As n (the sample size) approaches infinity, the distribution of $\\bar X$ approaches a normal distribution with:\n    - Mean: $\\mu$\n    - Standard Deviation: $\\sigma/\\sqrt{n}$\n\n## CLT Example\n\n- **Imagine:** You're flipping a fair coin many times. \n    - Each flip is an independent event (heads or tails).\n    - The probability of heads/tails is the same for each flip.\n- **Now:** Calculate the average number of heads after each set of 10 flips, then each set of 100 flips, and so on.\n- **Observation:** As the number of flips in each set increases, the distribution of these averages will start to resemble a bell-shaped curve (normal distribution), even though the individual coin flips are not normally distributed.\n\n## CLT Implications\n\n- **Approximation:** Even if the underlying data is not normally distributed, the distribution of the sample means will be approximately normal for large enough sample sizes.\n- **Practical Rule:** A common rule of thumb is that the sample size (n) should be at least 30 for the CLT to provide a good approximation. However, this is a guideline, and the actual required sample size can vary depending on the shape of the original distribution.\n\n## Normal Example $n = 10$\n\nSimulating 500 samples of size 10 from a normal distribution with mean 5 and standard deviation of 2.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#rnorm(10, 5, 2)\nsims <- replicate(500, rnorm(10, 5, 2))\nsims_mean <- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(10)),\n                col = \"red\")\n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n\n\n## Normal Example $n = 30$\n\nSimulating 500 samples of size 30 from a normal distribution with mean 5 and standard deviation of 2.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# rnorm(30, 5, 2)\nsims <- replicate(500, rnorm(30, 5, 2))\nsims_mean <- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(30)),\n                col = \"red\")\n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n\n\n\n## Normal Example $n = 50$\n\nSimulating 500 samples of size 50 from a normal distribution with mean 5 and standard deviation of 2.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# rnorm(50, 5, 2)\nsims <- replicate(500, rnorm(50, 5, 2))\nsims_mean <- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(50)),\n                col = \"red\")\n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\n\n## Normal Example $n = 100$\n\nSimulating 500 samples of size 100 from a normal distribution with mean 5 and standard deviation of 2.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# rnorm(100, 5, 2)\nsims <- replicate(500, rnorm(100, 5, 2))\nsims_mean <- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(100)),\n                col = \"red\")\n```\n\n::: {.cell-output-display}\n![](9_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n\n\n# Common Sampling Distributions\n\n## Normal DGP\n\nWhen the data is said to have a normal distribution (DGP), there are special properties with both the mean and standard deviation, regardless of sample size.\n\n## Statistics\n\n::: {.columns}\n::: {.column}\n**Mean**\n$$\n\\bar X = \\sum ^n_{i=1} X_i\n$$\n:::\n::: {.column}\n**Standard Deviation**\n$$\ns^2 = \\frac{1}{n}\\sum ^n_{i=1} (X_i - \\bar X)^2\n$$\n\n:::\n:::\n\n\n## When the true $\\mu$ and $\\sigma$ are known\nA data sample of size $n$ is generated from:\n$$\nX_i \\sim N(\\mu, \\sigma)\n$$\n\n## Distribution of $\\bar X$\n\n$$\n\\bar X \\sim N(\\mu, \\sigma/\\sqrt{n})\n$$\n\n## Distribution of Z\n\n$$\nZ = \\frac{\\bar X - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)\n$$\n\n## When the true $\\mu$ and $\\sigma$ are unknown\nA data sample of size $n$ is generated from:\n$$\nX_i \\sim N(\\mu, \\sigma)\n$$\n\n## Distribution of $s^2$ (unknown $\\mu$)\n$$\n(n-1)s^2/\\sigma^2 \\sim \\chi^2(n-1)\n$$\n\n## Distribution of Z (unknown $\\sigma$)\n\n$$\nZ = \\frac{\\bar X - \\mu}{\\sigma/\\sqrt{n}} \\rightarrow \\frac{\\bar X - \\mu}{s/\\sqrt{n}} \\sim t(n-1)\n$$\n\n\n\n# Sampling Distributions for Regression Models\n\n\n## Regression Coefficients\n\nThe estimates of regression coefficients (slopes) have a distribution!\n\n::: fragment\n\nBased on our outcome, we will have 2 different distributions to work with: Normal or t.\n\n:::\n\n## Linear Regression\n\n$$\n\\frac{\\hat\\beta_j-\\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim t_{n-p^\\prime}\n$$\n\n\n## $\\beta_j = 0$\n\n$$\n\\frac{\\hat\\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim t_{n-p^\\prime}\n$$\n\n\n## Logistic Regression\n\n$$\n\\frac{\\hat\\beta_j - \\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim N(0,1)\n$$\n\n## $\\beta_j = 0$\n\n$$\n\\frac{\\hat\\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim N(0,1)\n$$\n",
    "supporting": [
      "9_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}