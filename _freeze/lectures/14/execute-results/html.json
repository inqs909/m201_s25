{
  "hash": "ec32a05f6b4135a6ec3c1dc026910e56",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Inference with Linear Regression\"\ndate: 4/15/25\ndescription: |\n  Begins the discussion for linear regression.\n\nformat:\n  revealjs:\n    width: 1200\n    scrollable: true\n    theme: [default, styles.scss]\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: notes/chalkboard_1a.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    code-fold: true\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n  - reveal-auto-agenda\neditor: source\n---\n\n\n\n\n\n\n# Motivating Example\n\n## Motivating Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\np1 <- penguins |> ggplot(aes(x=species, y = body_mass_g)) +\n  geom_jitter() + \n  geom_boxplot() + \n  labs(x = \"Species\", y = \"Body Mass\")\n  \np2 <- penguins |> ggplot(aes(x=flipper_length_mm, y = body_mass_g)) +\n  geom_point() + \n  labs(x = \"Flipper Length\", y = \"Body Mass\")  \n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](14_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n\n\n# Mathematical Models\n\n## Mathematical Models\n\n## Standard Normal Distribution\n\n::: columns\n::: {.column width=\"50%\"}\n$$\n{\\frac{1}{\\sqrt{2 \\pi}}} e^{-\\frac{1}{2}x^2}\n$$\n:::\n\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(x = seq(-5,5, length.out = 100), \n           y1 = dt(seq(-5,5, length.out = 100), 1),\n           y2 = dt(seq(-5,5, length.out = 100), 10),\n           y3 = dt(seq(-5,5, length.out = 100), 30),\n           y4 = dt(seq(-5,5, length.out = 100), 100),\n           y5 = dnorm((seq(-5,5, length.out = 100)))) |> \n  ggplot() +\n  # geom_line(aes(x, y1, color = \"1\")) +\n  # geom_line(aes(x, y2, color = \"10\")) +\n  # geom_line(aes(x, y3, color = \"30\")) +\n  # geom_line(aes(x, y4, color = \"100\")) +\n  geom_line(aes(x, y5)) +\n  ylab(\"y\")\n```\n\n::: {.cell-output-display}\n![](14_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n:::\n:::\n\n## t Distribution\n\n::: columns\n::: {.column width=\"50%\"}\n$$\n\\frac{\\Gamma \\left(\\frac{v+1}{2}\\right)}{\\sqrt{\\pi v}\\Gamma\\left(\\frac{v}{2}\\right)} \\left(1 + \\frac{x^2}{v}\\right)^{-\\frac{v+1}{2}}\n$$\n:::\n\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(x = seq(-5,5, length.out = 100), \n           y1 = dt(seq(-5,5, length.out = 100), 1),\n           y2 = dt(seq(-5,5, length.out = 100), 10),\n           y3 = dt(seq(-5,5, length.out = 100), 30),\n           y4 = dt(seq(-5,5, length.out = 100), 100),\n           y5 = dnorm((seq(-5,5, length.out = 100)))) |> \n  ggplot() +\n  geom_line(aes(x, y1, color = \"1\")) +\n  geom_line(aes(x, y2, color = \"10\")) +\n  geom_line(aes(x, y3, color = \"30\")) +\n  geom_line(aes(x, y4, color = \"100\")) +\n  geom_line(aes(x, y5, color = \"Normal\")) +\n  ylab(\"y\")\n```\n\n::: {.cell-output-display}\n![](14_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n:::\n:::\n\n# $\\beta$ Hypothesis Testing\n\n## Hypothesis\n\n::: columns\n::: {.column width=\"50%\"}\n$$H_0: \\beta = \\theta$$\n:::\n\n::: {.column width=\"50%\"}\n$$H_0: \\beta \\ne \\theta$$\n:::\n:::\n\n## Testing $\\beta_j$\n\n$$\nT = \\frac{\\hat\\beta_j-\\theta}{\\mathrm{se}(\\hat\\beta_j)} \\sim t_{n-p^\\prime}\n$$\n\n-   $n$: sample size\n-   $p^\\prime$: number of $\\beta$s\n\n## P-Value\n\n| Alternative Hypothesis | p-value                       |\n|------------------------|-------------------------------|\n| $\\beta>\\theta$         | $P(\\hat\\beta >T)=p$           |\n| $\\beta<\\theta$         | $P(\\hat\\beta < T)=p$          |\n| $\\beta\\ne\\theta$       | $2\\times P(\\hat\\beta >|T|)=p$ |\n\n## Confidence Intervals\n\n$$\n\\hat \\beta_j \\pm CV \\times se(\\hat\\beta_j)\n$$\n\n-   $CV$: Critical Value $P(X<CV) = 1-\\alpha/2$\n\n-   $\\alpha$: significance level\n\n-   $se$: Standard Error Function\n\n## Conducting HT of $\\beta_j$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nxlm <- lm(Y ~ X, data = DATA)\nsummary(xlm)\n```\n:::\n\n\n\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nm1 <- lm(body_mass_g ~ species + flipper_length_mm, penguins)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ species + flipper_length_mm, data = penguins)\n#> \n#> Residuals:\n#>    Min     1Q Median     3Q    Max \n#> -898.8 -252.0  -24.8  229.8 1191.6 \n#> \n#> Coefficients:\n#>                   Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)       -4013.18     586.25  -6.846 3.74e-11 ***\n#> speciesChinstrap   -205.38      57.57  -3.568 0.000414 ***\n#> speciesGentoo       284.52      95.43   2.981 0.003083 ** \n#> flipper_length_mm    40.61       3.08  13.186  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 373.3 on 329 degrees of freedom\n#> Multiple R-squared:  0.787,\tAdjusted R-squared:  0.7851 \n#> F-statistic: 405.3 on 3 and 329 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n## Confidence Interval\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nconfint(xlm, level = LEVEL)\n```\n:::\n\n\n\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nconfint(m1, level = 0.90)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                           5 %        95 %\n#> (Intercept)       -4980.19064 -3046.16714\n#> speciesChinstrap   -300.33123  -110.41973\n#> speciesGentoo       127.11143   441.93578\n#> flipper_length_mm    35.52645    45.68588\n```\n\n\n:::\n:::\n\n\n\n\n# Model Hypothesis Testing\n\n## Model inference\n\nWe conduct model inference to determine if different models are better at explaining variation. A common example is to compare a linear model ($\\hat Y=\\hat\\beta_0 + \\hat\\beta_1 X$) to the mean of Y ($\\hat \\mu_y$). We determine the significance of the variation explained using an Analysis of Variance (ANOVA) table and F test.\n\n## Model Inference\n\nGiven 2 models:\n\n$$\n\\hat Y = \\hat\\beta_0 + \\hat\\beta_1 X_1 + \\hat\\beta_2 X_2 + \\cdots + \\hat\\beta_p X_p\n$$\n\nor\n\n$$\n\\hat Y = \\bar y\n$$\n\n::: fragment\nIs the model with predictors do a better job than using the average?\n:::\n\n## ANOVA\n\n## ANOVA Table\n\n| Source | DF        | SS            | MS                    | F                        |\n|---------------|---------------|---------------|---------------|---------------|\n| Model  | $DFR=k-1$ | $SSR$         | $MSR=\\frac{SSM}{DFR}$ | $\\hat F=\\frac{MSR}{MSE}$ |\n| Error  | $DFE=n-k$ | $SSE$         | $MSE=\\frac{SSE}{DFE}$ |                          |\n| Total  | $TDF=n-1$ | $TSS=SSR+SSE$ |                       |                          |\n\n$$\n\\hat F \\sim F(DFR, DFE)\n$$\n\n## Conducting an ANOVA in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nxlm <- lm(Y ~ X, data = DATA)\nsummary(xlm)\n```\n:::\n\n\n\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ species + flipper_length_mm, data = penguins)\n#> \n#> Residuals:\n#>    Min     1Q Median     3Q    Max \n#> -898.8 -252.0  -24.8  229.8 1191.6 \n#> \n#> Coefficients:\n#>                   Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)       -4013.18     586.25  -6.846 3.74e-11 ***\n#> speciesChinstrap   -205.38      57.57  -3.568 0.000414 ***\n#> speciesGentoo       284.52      95.43   2.981 0.003083 ** \n#> flipper_length_mm    40.61       3.08  13.186  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 373.3 on 329 degrees of freedom\n#> Multiple R-squared:  0.787,\tAdjusted R-squared:  0.7851 \n#> F-statistic: 405.3 on 3 and 329 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n## Model Inference\n\nModel inference can be extended to compare models that have different number of predictors.\n\n## Model Inference\n\nGiven:\n\n$$\nM1:\\ \\hat y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 \n$$\n\n$$\nM2:\\ \\hat y = \\beta_0 + \\beta_1 X_1  \n$$\n\nLet $M1$ be the FULL (larger) model, and let $M2$ be the RED (Reduced, smaller) model.\n\n## Model Inference\n\nHe can test the following Hypothesis:\n\n-   $H_0$: The error variations between the FULL and RED model are not different.\n-   $H_1$: The error variations between the FULL and RED model are different.\n\n## Test Statistic\n\n$$\n\\hat F = \\frac{[SSE(RED) - SSE(FULL)]/[DFE(RED)-DFE(FULL)]}{MSE(FULL)} \n$$\n\n$$\n\\hat F \\sim F[DFE(RED) - DFE(FULL), DFE(FULL)]\n$$\n\n## ANOVA in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nfull <- lm(Y  ~  X1 + X2 + X3 + X4)\nred <- lm(Y ~ X1 + X2)\nanova(red, full)\n```\n:::\n\n\n\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nm1 <- lm(body_mass_g ~ species + island + flipper_length_mm, penguins)\nm2 <- lm(body_mass_g ~ island + flipper_length_mm, penguins)\nanova(m2, m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Analysis of Variance Table\n#> \n#> Model 1: body_mass_g ~ island + flipper_length_mm\n#> Model 2: body_mass_g ~ species + island + flipper_length_mm\n#>   Res.Df      RSS Df Sum of Sq      F    Pr(>F)    \n#> 1    329 47774435                                  \n#> 2    327 45552857  2   2221579 7.9738 0.0004157 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n# Model Assumptions\n\n## Model Assumptions\n\nWhen we are conducting inference linear regression, we will have to check the following conditions:\n\n-   Linearity\n-   Independence\n-   Normality\n-   Equal Variances\n-   Multicollinearity (for MLR)\n\n## Linearity\n\nProbably considered the most important assumption, but there must be a linear relationship between both the outcome variable (y) and a set of predictors ($x_1$, $x_2$, ...).\n\n## Independence\n\nThe data points must not influence each other.\n\n## Normality\n\nThe model errors (also known as residuals) must follow a normal distribution.\n\n## Equal Variances\n\nThe variability of the data points must be the same for all predictor values.\n\n## Residuals\n\nResiduals are the errors between the observed value and the estimated model. Common residuals include\n\n-   Raw Residual\n\n-   Standardized Residual\n\n-   Jackknife (studentized) Residuals\n\n## Influential Measurements\n\nInfluential measures are statistics that determine how much a data point affects the model. Common influential measures are\n\n-   Leverages\n\n-   Cook's Distance\n\n## Raw Residuals\n\n$$\n\\hat r_i = y_i - \\hat y_i\n$$\n\n## Residual Analysis\n\nA residual analysis is used to test the assumptions of linear regression.\n\n## QQ Plot\n\nA qq (quantile-quantile) plot will plot the estimated quantiles of the residuals against the theoretical quantiles from a normal distribution function. If the points from the qq-plot lie on the $y=x$ line, it is said that the residuals follow a normal distribution.\n\n## Residual vs Fitted Plot\n\nThis plot allows you to assess the linearity, constant variance, and identify potential outliers. Create a scatter plot between the fitted values (x-axis) and the raw/standardized residuals (y-axis).\n\n## Variance Inflation Factor\n\nThe variance inflation factor is a measurement on how much variables are collinear with each other. A value greater than 10 is a cause for concern and action should be taken.\n\n## Residual Analysis in R\n\nUse the `resid_df` function to obtain the residuals of a model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrdf <- resid_df(LM_OBJECT)\n```\n:::\n\n\n\n\n## Residual vs Fitted Plot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nggplot(RDF, aes(fitted, resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, col = \"red\")\n```\n:::\n\n\n\n\n## QQ Plot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nggplot(RDF, aes(sample = resid)) + \n  stat_qq() +\n  stat_qq_line() \n```\n:::\n\n\n\n\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nxlm <- lm(body_mass_g ~   island + species + flipper_length_mm,\n          penguins)\ndfxlm <- resid_df(xlm)\n\nggplot(dfxlm, aes(fitted, resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, col = \"red\")\n\nggplot(dfxlm, aes(sample = resid)) + \n  stat_qq() +\n  stat_qq_line() \n```\n:::\n",
    "supporting": [
      "14_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}