{
  "hash": "165e3499d76960d3899afd739cdc15ec",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Statistical Inference\"\ndate: 4/10/25\ndescription: |\n  Statistical Inference\n\nformat:\n  revealjs:\n    width: 1200\n    scrollable: true\n    sc-sb-title: true\n    footer: <https://m201.inqs.info/lectures/10>\n    theme: [default, styles.scss]\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    code-fold: true\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n  - reveal-auto-agenda\n\neditor: source\n---\n\n\n\n\n\n\n# Statistical Inference\n\n## What is Statistical Inference?\n\n-   Drawing conclusions about a **population** based on a **sample**\n-   Population = entire group\n-   Sample = subset\n\n::: notes\nIntroduce the big idea: We want to make st\n:::\n\n## Two Main Types of Inference\n\n1.  Estimation\\\n2.  Hypothesis Testing\n\n::: notes\nWe'll be focusing on two fundamental techniques in inference. First, estimating population values (like the mean), and second, testing claims about the population.\n:::\n\n## Estimation\n\n- **Point Estimate**: Single best guess (e.g., $\\hat \\beta_1$)\n- **Interval Estimate**: Range likely to contain the true value\n\n::: notes\nPoint estimates are easy but not very informative. Intervals give us a sense of uncertainty, which is critical in inference.\n:::\n\n## Hypothesis Testing\n\n- $H_0$: No effect or difference\\\n- $H_1$: Some effect or difference\\\n- We use sample data to support or reject $H_0$\n\n::: notes\nMention that $H_0$ is the default assumption. We only reject it if the data give us strong enough evidence.\n:::\n\n## Key Concepts and Tools\n\n- Sampling Distribution\n- Central Limit Theorem\n- Standard Error\n\n::: notes\nThese three concepts are foundational. Understanding them helps us assess how reliable our estimates are.\n:::\n\n## p-values\n\n-   Probability of observing data as extreme as this if $H_0$ is true\n\nMisinterpretation of p-values is common. Emphasize: low p-value means data is unusual under $H_0$.\n\n## Confidence Intervals\n\n-   A range where we expect the true value to fall\n\n::: notes\nClarify interpretation: it's not about the probability the parameter is inside the interval, but about the method producing accurate intervals in the long run.\n:::\n\n# Hypothesis Testing\n\n## Hypothesis Tests\n\nHypothesis tests are used to test whether claims are valid or not. This is conducted by collecting data, setting the **Null** and **Alternative** Hypothesis.\n\n## Null Hypothesis $H_0$\n\nThe null hypothesis is the claim that is initially believed to be true. For the most part, it is always equal to the hypothesized value.\n\n## Alternative Hypothesis $H_a$\n\nThe alternative hypothesis contradicts the null hypothesis.\n\n## Example of Null and Alternative Hypothesis\n\nWe want to see if $\\beta$ is different from $\\beta^*$\n\n| Null Hypothesis        | Alternative Hypothesis |\n|------------------------|------------------------|\n| $H_0: \\beta=\\beta^*$   | $H_a: \\beta\\ne\\beta^*$ |\n| $H_0: \\beta\\le\\beta^*$ | $H_a: \\beta>\\beta^*$   |\n| $H_0: \\beta\\ge\\beta^*$ | $H_0: \\beta<\\beta^*$   |\n\n## One-Side vs Two-Side Hypothesis Tests\n\nNotice how there are 3 types of null and alternative hypothesis, The first type of hypothesis ($H_a:\\beta\\ne\\beta^*$) is considered a 2-sided hypothesis because the rejection region is located in 2 regions. The remaining two hypotheses are considered 1-sided because the rejection region is located on one side of the distribution.\n\n| Null Hypothesis        | Alternative Hypothesis | Side    |\n|------------------------|------------------------|---------|\n| $H_0: \\beta=\\beta^*$   | $H_a: \\beta\\ne\\beta^*$ | 2-Sided |\n| $H_0: \\beta\\le\\beta^*$ | $H_a: \\beta>\\beta^*$   | 1-Sided |\n| $H_0: \\beta\\ge\\beta^*$ | $H_0: \\beta<\\beta^*$   | 1-Sided |\n\n## Hypothesis Testing Steps\n\n1.  State $H_0$ and $H_1$\n2.  Choose $\\alpha$\n3.  Compute confidence interval/p-value\n4.  Make a decision\n\n::: notes\nWalk through the steps slowly with an example in mind. Emphasize that $\\alpha$ is a threshold, not the actual probability of error.\n:::\n\n## Rejection Region\n\n\n\n## Rejection Region\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nalpha <- 0.05\n\n# Critical values for two-tailed test\nz_critical <- qnorm(1 - alpha / 2)\n\n# Create data for the normal curve\nx <- seq(-4, 4, length = 1000)\ny <- dnorm(x)\n\ndf <- data.frame(x = x, y = y)\n\nggplot(df, aes(x = x, y = y)) +\n  geom_line(color = \"deepskyblue\", size = 1) +\n  geom_area(data = subset(df, x <= -z_critical), aes(y = y), fill = \"firebrick\", alpha = 0.5) +\n  geom_area(data = subset(df, x >= z_critical), aes(y = y), fill = \"firebrick\", alpha = 0.5) +\n  geom_vline(xintercept = c(-z_critical, z_critical), linetype = \"dashed\", color = \"black\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](10_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n\n\n# Decision Making\n\n## Decision Making\n\nHypothesis Testing will force you to make a decision: Reject $H_0$ **OR** Fail to Reject $H_0$\n\n::: fragment\nReject $H_0$: The effect seen is not due to random chance, there is a process making contributing to the effect.\n:::\n\n::: fragment\nFail to Reject $H_0$: The effect seen is due to random chance. Random sampling is the reason why an effect is displayed, not an underlying process.\n:::\n\n## Decision Making: P-Value\n\nThe p-value approach is one of the most common methods to report significant results. It is easier to interpret the p-value because it provides the probability of observing our test statistics, or something more extreme, given that the null hypothesis is true.\n\n::: fragment\n**If** $p < \\alpha$, then you reject $H_0$; otherwise, you will fail to reject $H_0$.\n:::\n\n\n## Decision Making: Confidence Interval Approach\n\nThe confidence interval approach can evaluate a hypothesis test where the alternative hypothesis is $\\beta\\ne\\beta^*$. The bootstrapping approach will result in a lower and upper bound denoted as: $(LB, UB)$.\n\n::: fragment\n**If $\\beta^*$ is in $(LB, UB)$, then you fail to reject $H_0$. If $\\beta^*$ is not in $(LB,UB)$, then you reject $H_0$.**\n:::\n\n## Significance Level $\\alpha$\n\nThe significance level $\\alpha$ is the probability you will reject the null hypothesis given that it was true.\n\n::: fragment\nIn other words, $\\alpha$ is the error rate that a research controls.\n:::\n\n::: fragment\nTypically, we want this error rate to be small ($\\alpha = 0.05$).\n:::\n\n# Power Analysis\n\n## What is Statistical Power\n\n- **Statistical Power** is the probability of correctly rejecting a false null hypothesis.\n- In other words, it's the chance of **detecting a real effect** when it exists.\n\n## Why Power Matters\n\n- Low power → high risk of **Type II Error** (false negatives)\n- High power → better chance of finding true effects\n- Common threshold: **80% power**\n\n## Errors in Inference\n\n|         |                               |                         |\n|:--------|:------------------------------|:------------------------|\n| Type I  | Reject $H_0$ when true        | False positive          |\n| Type II | Don't reject $H_0$ when false | False negative          |\n| Power   | $1 - P(\\text{Type II})$       | Detecting a true effect |\n\n::: notes\nPower is often overlooked. It's about how sensitive the test is to real effects. Larger samples increase power.\n:::\n\n## Type I Error (False Positive)\n\n-   **Rejecting** $H_0$ when it is actually true\n-   Probability = $\\alpha$ (significance level)\n\n::: notes\nType I errors happen when we detect an effect that doesn't really exist. This is controlled by our chosen alpha level.\n:::\n\n## Type II Error (False Negative)\n\n-   **Failing to reject** $H_0$ when it is actually false\n-   Probability = $\\beta$\n-   Power = $1 - \\beta$\n\n::: notes\nType II errors are often due to small sample sizes or high variability. Power analysis helps us plan to avoid these.\n:::\n\n## Balancing Errors\n\n-   Lowering $\\alpha$ reduces Type I errors, but **increases** risk of Type II errors.\n-   To reduce both:\n    -   Increase sample size\n    -   Use more appropriate statistical tests\n\n::: notes\nThere's a trade-off between these errors. We can't eliminate both, but we can **manage** the risk based on the consequences of each type.\n:::\n\n## What Affects Power?\n\n1. **Effect Size**  \n   - Bigger effects are easier to detect\n\n2. **Sample Size ($n$)**  \n   - Larger samples reduce standard error\n\n3. **Significance Level ($\\alpha$)**  \n   - Higher $\\alpha$ increases power (but riskier!)\n\n4. **Variability**  \n   - Less noise in data = better power\n\n## Boosting Power\n\n- Power = Probability of rejecting $H_0$ when it's false\n- Helps avoid **Type II Errors**\n- Driven by:\n  - Sample size\n  - Effect size\n  - $\\alpha$\n  - Variability\n- Aim for **80% or higher**\n\n# Confidence Intervals\n\n## Confidence Intervals\n\n- A confidence interval gives a **range of plausible values** for a population parameter.\n- It reflects **uncertainty** in point estimates from sample data.\n\n::: notes\nIntroduce confidence intervals as the natural next step after understanding sampling variability and standard error. Emphasize that point estimates are useful, but intervals give a more complete picture.\n:::\n\n## Interpretation\n\n> \"We are 95% confident that the true mean lies between A and B.\"\n\n- This does **not** mean there's a 95% chance the mean is in that interval.\n- It means: if we repeated the sampling process many times, **95% of the intervals would contain the true value**.\n\n::: notes\nThis is one of the most common misconceptions. Clarify that the confidence is in the *method*, not any one interval.\n:::\n\n## Factors Affecting CI Width\n\n-   Sample size ($n$): larger $n$ → narrower CI\\\n-   Standard deviation ($s$ or $\\sigma$): more variability → wider CI\\\n-   Confidence level: higher confidence → wider CI\n\n::: notes\nUse this to summarize what controls how “precise” our confidence interval is. Give examples of each.\n:::\n\n# Linear Regression Inference in R\n\n## Conducting HT of $\\beta_j$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nxlm <- lm(Y ~ X, data = DATA)\nsummary(xlm)\n```\n:::\n\n\n\n\n-   `xlm`: name of the stored model\n-   `Y`: Name of the outcome variable in `DATA`\n-   `X`: Name of the Predictor Variable(s) in `DATA`\n-   `DATA`: Name of the data set\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nm1 <- lm(body_mass_g ~ species + flipper_length_mm, penguins)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ species + flipper_length_mm, data = penguins)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -927.70 -254.82  -23.92  241.16 1191.68 \n#> \n#> Coefficients:\n#>                    Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)       -4031.477    584.151  -6.901 2.55e-11 ***\n#> speciesChinstrap   -206.510     57.731  -3.577 0.000398 ***\n#> speciesGentoo       266.810     95.264   2.801 0.005392 ** \n#> flipper_length_mm    40.705      3.071  13.255  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 375.5 on 338 degrees of freedom\n#>   (2 observations deleted due to missingness)\n#> Multiple R-squared:  0.7826,\tAdjusted R-squared:  0.7807 \n#> F-statistic: 405.7 on 3 and 338 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n## Confidence Interval\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nconfint(xlm, level = LEVEL)\n```\n:::\n\n\n\n\n-   `xlm`: Name of the model saved in R\n-   `LEVEL`: A number between 0 and 1 to specify confidence level\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nconfint(m1, level = 0.90)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                           5 %        95 %\n#> (Intercept)       -4994.96108 -3067.99270\n#> speciesChinstrap   -301.72956  -111.29068\n#> speciesGentoo       109.68404   423.93517\n#> flipper_length_mm    35.64014    45.77066\n```\n\n\n:::\n:::\n\n\n\n\n# Linear Regression Example\n\n## Wage Data Example\n\nThe `Wage` data set contains data on 3000 male workers in the atlantic region. We are interested if there is a significant effect on the outcome `wage` based on the predictor variable `age`, adjusting for marital status (`maritl`), race (`race`),  and education level (`education`).\n\n\n## Red Wine Data\n\nThe [Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality) data set contains data on information on both red and white wine from North Portugal. We are interested in seeing if `density` of the red wine (predictor variable) affects the `quality` (outcome variable), adjusting for `alcohol`, `p_h`, `residual_sugar`, and `fixed_acidity`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nurl <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\nwine <- read_delim(url, delim = \";\")\n```\n:::\n\n\n\n\n# Logistic Regression Inference in R\n\n## Conducting HT of $\\beta_j$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nxlm <- glm(Y ~ X, data = DATA, family = binomial())\nsummary(xlm)\n```\n:::\n\n\n\n\n-   `xlm`: name of the stored model\n-   `Y`: Name of the outcome variable in `DATA`\n-   `X`: Name of the Predictor Variable(s) in `DATA`\n-   `DATA`: Name of the data set\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nm1 <- glm(death ~ recur + number + size, bladder1, family = binomial())\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm(formula = death ~ recur + number + size, family = binomial(), \n#>     data = bladder1)\n#> \n#> Coefficients:\n#>               Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept) -0.8525259  0.4462559  -1.910 0.056082 .  \n#> recur       -0.3897480  0.1062848  -3.667 0.000245 ***\n#> number       0.0008451  0.1124503   0.008 0.994004    \n#> size        -0.2240419  0.1626749  -1.377 0.168439    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 189.38  on 293  degrees of freedom\n#> Residual deviance: 166.43  on 290  degrees of freedom\n#> AIC: 174.43\n#> \n#> Number of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n\n\n## Confidence Interval\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nconfint(xlm, level = LEVEL)\n```\n:::\n\n\n\n\n-   `xlm`: Name of the model saved in R\n-   `LEVEL`: A number between 0 and 1 to specify confidence level\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nconfint(m1, level = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                  2.5 %      97.5 %\n#> (Intercept) -1.7353779  0.02529523\n#> recur       -0.6217831 -0.20078281\n#> number      -0.2421738  0.20731479\n#> size        -0.5880581  0.06061498\n```\n\n\n:::\n:::\n\n\n\n\n## Confidence Interval for Odds Ratio\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nexp(confint(m1, level = 0.95))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                 2.5 %    97.5 %\n#> (Intercept) 0.1763335 1.0256179\n#> recur       0.5369861 0.8180901\n#> number      0.7849197 1.2303698\n#> size        0.5554048 1.0624898\n```\n\n\n:::\n:::\n\n\n\n\n# Logistic Regression Example\n\n## Breast Cancer Data\n\nThe [Breast Cancer](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic) data set contains information about image diagnosis of individuals from Wisconsin. We are interested if breast cancer `diagnosis` (outcome variable; Benign or Malignant), is affected by tumor `radius`, adjusting for `texture`, `perimeter`, and `smoothness`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nurl <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\nbc <- read.csv(url, header = FALSE)\n\n# Add column names\ncolnames(bc) <- c(\"id\", \"diagnosis\", paste0(\"V\", 3:32))\n\n# Convert diagnosis to factor\nbc$diagnosis <- factor(bc$diagnosis, levels = c(\"B\", \"M\"), labels = c(\"Benign\", \"Malignant\"))\n```\n:::\n\n\n\n\n## Bank Note Classification\n\nThe [Bank Note](https://archive.ics.uci.edu/dataset/267/banknote+authentication) data set contains information about bank note authentication based on images. We are interested in seeing if `class` (outcome variable; real or fake) is associated by image `skewness` (predictor), adjusting for `variance`, and `entropy`.  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nurl <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\nbank <- read.csv(url, header = FALSE)\n\ncolnames(bank) <- c(\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\")\nbank$class <- factor(bank$class, levels = c(0, 1), labels = c(\"Genuine\", \"Forged\"))\n```\n:::",
    "supporting": [
      "10_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}