{
  "hash": "2e4b3f2db9d391e677fcb4b92af97f7d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Simple Linear Regression\"\ndate: 2/25/25\ndescription: |\n  Begins the discussion for linear regression.\n\nformat:\n  revealjs:\n    scrollable: true\n    theme: [default, styles.scss]\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n  - reveal-auto-agenda\neditor: source\n---\n\n\n\n\n\n\n\n# Modeling Relationships\n\n## Explaining Variation\n\n::: fragment\nThis is the process where we try to reduce the variation with the use of other variables.\n:::\n\n::: fragment\nCan be thought of as getting it less wrong when taking an educated guess.\n:::\n\n## Explaining Variation\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(body_mass_g)) +\n  geom_density() \n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n\n## Variation with One Variable\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(body_mass_g, fill = species)) +\n  geom_density(alpha = .5)\n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n\n\n# A Simple Model\n\n## Generated Model\n\n$$\nY \\sim DGP_1\n$$\n\n## A Simple Model\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(body_mass_g)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n\n## A Simple Model\n\n$$\nY = \\_\\_\\_ + error\n$$\n\n## Notation\n\n$$\nY = \\ \\ \\ \\ \\ \\ \\ \\ \\ + \\varepsilon \n$$\n\n## The Simple Generated Model\n\n$$\nY \\sim \\beta_0 + \\varepsilon\n$$\n\n$$\n\\varepsilon \\sim DGP_2\n$$\n\n::: fragment\n$DGP_2$ is not the same as the $DGP_1$, it is transformed due $\\beta_0$. Consider this the NULL $DGP$.\n:::\n\n## Observing Data\n\n$$\nY = \\beta_0 + \\varepsilon\n$$\n\n## Estimated Line\n\n$$\n\\hat Y=\\hat\\beta_0\n$$\n\n## Notation\n\n::: columns\n::: {.column width=\"50%\"}\n### Observed\n\n$$\nY = \\beta_0 + \\varepsilon\n$$\n:::\n\n::: {.column width=\"50%\"}\n### Estimated\n\n$$\n\\hat Y = \\hat \\beta_0\n$$\n:::\n:::\n\n# Modelling Data\n\n## Indexing Data\n\nThe data in a data set can be indexed by a number.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins[1,-c(1:2)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 Ã— 6\n#>   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex    year\n#>            <dbl>         <dbl>             <int>       <int> <fct> <int>\n#> 1           39.1          18.7               181        3750 male   2007\n```\n\n\n:::\n:::\n\n\n\n\n::: fragment\nMaking the variable \"body_mass_g\" be represented by $Y$ and \"flipper_length_mm\" as $X$:\n\n$$\nY_1 = 3750 \\ \\ X_1=181\n$$\n\n:::\n\n## Indexing Data\n\n$$\nY_i, X_i\n$$\n\n## Data\n\nWith the data that we collect from a sample, we hypothesize how the data was generated.\n\n::: fragment\nUsing a simple model:\n\n$$\nY_i = \\beta_0 + \\varepsilon_i\n$$\n\n:::\n\n## Estimated Value\n\n$$\n\\hat Y_i = \\hat \\beta_0\n$$\n\n## Estimation \n\nTo estimate $\\hat \\beta_0$, we minimize the follow function:\n\n$$\n\\sum^n_{i=1} (Y_i-\\hat Y_i)^2\n$$\n\n::: fragment\nThis is known as the sum squared errors, SSE \n:::\n\n\n## Residuals\n\nThe residuals are known as the observed errors from the data in the model:\n\n$$\nr_i = Y_i - \\hat Y_i\n$$\n\n## Estimation in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Y ~ 1, data = DATA)\n```\n:::\n\n\n\n\n\n- `Y`: Name Outcome Variable of Interest in data frame `DATA`\n- `DATA`: Name of the data frame\n\n## Modeling Body Mass in Penguins\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(body_mass_g ~ 1, data = penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ 1, data = penguins)\n#> \n#> Coefficients:\n#> (Intercept)  \n#>        4207\n```\n\n\n:::\n:::\n\n\n\n\n::: fragment\n\n$$\n\\hat Y = 4207\n$$\n\n:::\n\n\n## Visualize\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(body_mass_g)) +\n  geom_density() +\n  geom_vline(xintercept = 4207)\n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n\n\n# Linear Model\n\n## Linear Model\n\nThe goal of Statistics is to develop models the have a better explanation of the outcome $Y$.\n\n::: fragment\nIn particularly, reduce the sum of squared errors.\n:::\n\n::: fragment\nBy utilizing a bit more of information, $X$, we can increase the predicting capabilities of the model.\n:::\n\n::: fragment\nThus, the linear model is born.\n:::\n\n## Visualization\n\n::: panel-tabset\n\n### 1-Dimensional\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(body_mass_g)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n\n### 2-Dimensional\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, fill = after_stat(level))) +\n  stat_density_2d(geom = \"polygon\")\n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n\n\n:::\n\n## Linear Model\n\n$$\nY = \\beta_0 + \\beta_1 X + \\varepsilon\n$$\n\n$$\n\\varepsilon \\sim DGP_3\n$$\n\n## Scatter Plot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(flipper_length_mm, body_mass_g)) + \n  geom_point() \n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n\n## Imposing a Line\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(flipper_length_mm, body_mass_g)) + \n  geom_point() +\n  stat_smooth(method = \"lm\", se = F) \n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\n\n## Modelling the Data\n\n$$\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\n$$\n\n## Linear Model\n\n$$\n\\hat Y_i = \\hat \\beta_0 + \\hat \\beta_1 X_i\n$$\n\n::: fragment\nGoal is to obtain numerical values for $\\hat \\beta_0$ and $\\hat \\beta_1$ that will minimize the SSE.\n:::\n\n## SSE\n\n$$\n\\sum^n_{i=1} (Y_i-\\hat Y_i)^2\n$$\n\n\n$$\n\\hat Y_i = \\hat \\beta_0 + \\hat \\beta_1 X_i\n$$\n\n## Fitting a Model in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Y ~ X, data = DATA)\n```\n:::\n\n\n\n\n- `X`: Name Predictor Variable of Interest in data frame `DATA`\n- `Y`: Name Outcome Variable of Interest in data frame `DATA`\n- `DATA`: Name of the data frame\n\n## Example\n\n\nY: \"body_mass_g\"; X: \"flipper_length_mm\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(body_mass_g ~ flipper_length_mm, data = penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ flipper_length_mm, data = penguins)\n#> \n#> Coefficients:\n#>       (Intercept)  flipper_length_mm  \n#>          -5872.09              50.15\n```\n\n\n:::\n:::\n\n\n\n\n\n$$\n\\hat Y_i = -5872.09 + 50.15 X_i\n$$\n\n\n## Interpretation of $\\hat\\beta_0$\n\nThe intercept $\\hat \\beta_0$ can be interpreted as the base value when $X$ is set to 0.\n\n::: fragment\nSome times the intercept can be interpretable to real world scenarios.\n:::\n\n::: fragment\nOther times it cannot.\n:::\n\n## Interpreting Example\n\n$$\n\\hat Y_i = -5872.09 + 50.15 X_i\n$$\n\nWhen flipper length is 0 mm, the body mass is -5872 grams.\n\n## Interpretation of $\\hat \\beta_1$\n\nThe slope $\\hat \\beta_1$ indicates how will y change when x increases by 1 unit.\n\n::: fragment\nIt will demonstrate if there is, on average, a positive or negative relationship based on the sign provided.\n:::\n\n## Interpreting Example\n\n$$\n\\hat Y_i = -5872.09 + 50.15 X_i\n$$\n\nWhen flipper length increases by 1 mm, the body mass will increase by 50.15 grams.\n\n\n# Categorical Variables\n\n## Body Mass with Species\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(body_mass_g)) +\n  geom_boxplot() \n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n\n\n## Body Mass with Species\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(body_mass_g, fill = species)) +\n  geom_boxplot() \n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\n\n\n## Group Statistics\n\nWe can use statistics to explain a continuous variable by the categories.\n\n::: fragment\nCompute statistics for each group.\n:::\n\n::: fragment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_by_cat_stats(DATA, NUM, CAT)\n```\n:::\n\n\n\n:::\n\n\n## Compute Group Statistics\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_by_cat_stats(penguins, body_mass_g, species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>   Categories  min    q25     mean median  q75  max      sd      var   iqr\n#> 1     Adelie 2850 3362.5 3706.164   3700 4000 4775 458.620 210332.4 637.5\n#> 2  Chinstrap 2700 3487.5 3733.088   3700 3950 4800 384.335 147713.5 462.5\n#> 3     Gentoo 3950 4700.0 5092.437   5050 5500 6300 501.476 251478.3 800.0\n#>   missing\n#> 1       0\n#> 2       0\n#> 3       0\n```\n\n\n:::\n:::\n\n\n\n\n\n## LM with Categorical Variables\n\nA line is normally used to model 2 continuous variables.\n\n::: fragment\nHowever, the predictor variable $X$ can be restricted to a set a variables that can symbolize categories.\n:::\n\n::: fragment\nA category will be used as a reference for a model.\n:::\n\n\n## Binary (Dummy) Variables\n\nBinary variables are variable that can only take on the value 0 or 1.\n\n$$\nD_i = \\left\\{\n\\begin{array}{cc}\n1 & Category\\\\\n0 & Other\n\\end{array}\n\\right.\n$$\n\n## Binary (Dummy) Variables\n\nTo fit a model with categorical variables, we must utilize dummy (binary) variables that indicate which category is being referenced. We use $C-1$ dummy variables where $C$ indicates the number of categories. When coded correctly, each category will be represented by a combination of dummy variables.\n\n## Example\n\nIf we have 4 categories, we will need 3 dummy variables:\n\n|         | Cat 1 | Cat 2 | Cat 3 | Cat 4 |\n|---------|-------|-------|-------|-------|\n| Dummy 1 | 1     | 0     | 0     | 0     |\n| Dummy 2 | 0     | 1     | 0     | 0     |\n| Dummy 2 | 0     | 0     | 1     | 0     |\n\n\n## Species Dummy Variables\n\n|         | Chinstrap | Gentoo | Adelie |\n|---------|-------|-------|-------|\n| $D_1$ | 1     | 0     | 0     |\n| $D_2$ | 0     | 1     | 0     |\n\n## Linear Model\n\n$$\n\\hat Y_i = \\hat \\beta_0 + \\hat\\beta_1 D_{1i} + \\hat\\beta_2 D_{2i}\n$$\n\n::: fragment\n$\\hat \\beta_1$ indicates how body mass changes from Adelie to Chinstrap.\n:::\n\n::: fragment\n$\\hat \\beta_2$ indicates how body mass changes from Adelie to Gentoo.\n:::\n\n::: fragment\n$\\hat \\beta_0$ represents the baseline level, in this case the body mass of Adelie.\n:::\n\n## Fitting a Model in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Y ~ X, data = DATA)\n```\n:::\n\n\n\n\n- `X`: Name Predictor Variable of Interest in data frame `DATA`, must be a factor variable\n- `Y`: Name Outcome Variable of Interest in data frame `DATA`\n- `DATA`: Name of the data frame\n\n## X not a Factor\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Y ~ factor(X), data = DATA)\n```\n:::\n\n\n\n\n- `X`: Name Predictor Variable of Interest in data frame `DATA`, not a factor variable\n- `Y`: Name Outcome Variable of Interest in data frame `DATA`\n- `DATA`: Name of the data frame\n\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(body_mass_g ~ species, penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ species, data = penguins)\n#> \n#> Coefficients:\n#>      (Intercept)  speciesChinstrap     speciesGentoo  \n#>          3706.16             26.92           1386.27\n```\n\n\n:::\n:::\n\n\n\n\n$$\n\\hat Y_i = 3706 + 26.92 D_{1i} + 1386.27 D_{2i}\n$$\n\n## Finding the Adelie MASS\n\n$$\n\\hat Y_i = 3706 + 26.92 (0) + 1386.27 (0)\n$$\n\n## Finding the Chinstrap MASS\n\n$$\n\\hat Y_i = 3706 + 26.92 (1) + 1386.27 (0)\n$$\n\n## Finding the Gentoo MASS\n\n$$\n\\hat Y_i = 3706 + 26.92 (0) + 1386.27 (1)\n$$\n\n## Intepreting $\\hat \\beta_1$\n\nOn average, Chinstrap has a larger mass than Adelie by about 26.92 grams.\n\n## Intepreting $\\hat \\beta_2$\n\nOn average, Gentoo has a larger mass than Adelie by about 1386.27 grams.\n\n# Strength and Correlation\n\n## Correlation\n\nCorrelation is a statistics that can be used to describe the strength of the relationship between 2 continuous variables.\n\n::: fragment\n$$\nr = \\frac{1}{n-1}\\sum^n_{i=1}\\frac{x_i - \\bar x}{s_x}\\frac{y_i - \\bar y}{s_y}\n$$\n\n-   $\\bar x$, $\\bar y$: sample means\n-   $s_x$, $s_y$: sample standard deviations\n\n:::\n\n::: fragment\n$$\n-1 \\leq r \\leq 1\n$$\n:::\n\n\n## Correlations\n\n![From IMS 2e](https://openintro-ims.netlify.app/model-slr_files/figure-html/fig-posNegCorPlots-1.png)\n\n## Coefficient of Determination\n\nThe coefficient of determination evaluates the strength between an outcome $Y$ and the linear model, which includes $X$.\n\n::: fragment\n$$\nR^2 = r^2\n$$\n:::\n\n::: fragment\n$$\n0 \\leq R^2 \\leq 1\n$$\n:::\n\n::: fragment\nThe coefficient of determination measures the total variation explained by the linear model. The closer to 1, the better the linear model.\n:::\n\n## Correlation in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(DATA$Y, DATA$X)\n```\n:::\n\n\n\n\n- `X`: Name Predictor Variable of Interest in data frame `DATA`\n- `Y`: Name Outcome Variable of Interest in data frame `DATA`\n- `DATA`: Name of the data frame\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(penguins$body_mass_g, penguins$flipper_length_mm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.8729789\n```\n\n\n:::\n:::\n\n\n\n\n## Coefficient of Determination in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxlm <- lm(Y ~ X, data = DATA)\nr2(xlm)\n```\n:::\n\n\n\n\n- `X`: Name Predictor Variable of Interest in data frame `DATA`\n- `Y`: Name Outcome Variable of Interest in data frame `DATA`\n- `DATA`: Name of the data frame\n\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxlm <- lm(body_mass_g ~ species, penguins)\nr2(xlm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.6744887\n```\n\n\n:::\n:::\n\n\n\n\n# Prediction\n\n## Statistical Model\n\n$$\n\\hat Y = \\hat \\beta_0 + \\hat \\beta_1 X\n$$\n\n- $X$: Input\n- $\\hat Y$: Output\n\n## Prediction\n\nUsing the equation $\\hat Y$, we can give it a value of $X$ and then, in return, a value of $\\hat Y$ that predicts the true value $Y$.\n\n## Prediction in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxlm <- lm(Y ~ X,\n            data = DATA)\n\npredict_df <- data.frame(X = VAL)\n\npredict(xlm,\n        predict_df)\n```\n:::\n\n\n\n- `X`: Name Predictor Variable of Interest in data frame `DATA`\n- `Y`: Name Outcome Variable of Interest in data frame `DATA`\n- `DATA`: Name of the data frame\n- `VAL`: Value for the Predictor Variable\n\n\n## Example 1\n\n::: panel-tabset\n\n### Example\n\nPredict the body mass for a gentoo penguin.\n\n### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxlm <- lm(body_mass_g ~ species,\n            data = penguins)\n\nxlm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ species, data = penguins)\n#> \n#> Coefficients:\n#>      (Intercept)  speciesChinstrap     speciesGentoo  \n#>          3706.16             26.92           1386.27\n```\n\n\n:::\n\n```{.r .cell-code}\npredict_df <- data.frame(species = \"Gentoo\")\n\npredict(xlm,\n        predict_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>        1 \n#> 5092.437\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n## Example 2\n\n\n::: panel-tabset\n\n### Example\n\nPredict the body mass for a penguin with a flipper length of 190.\n\n### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxlm <- lm(body_mass_g ~ flipper_length_mm,\n            data = penguins)\n\n\nxlm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ flipper_length_mm, data = penguins)\n#> \n#> Coefficients:\n#>       (Intercept)  flipper_length_mm  \n#>          -5872.09              50.15\n```\n\n\n:::\n\n```{.r .cell-code}\npredict_df <- data.frame(flipper_length_mm = 190)\n\npredict(xlm,\n        predict_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>        1 \n#> 3657.028\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n## Interpolation\n\nInterpolation is the process of estimating a value within the range of the observed input data $X$. \n\n## Extrapolation\n\nExtrapolation is the process of estimating a value beyond the range of observed input data $X$. It's about venturing into the unknown, using what we know as a guide.\n\n## Extrapolation\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(flipper_length_mm, body_mass_g)) + \n  xlim(160, 250) +\n  ylim(2600, 7000) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = F) \n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-29-1.png){width=960}\n:::\n:::\n",
    "supporting": [
      "7_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}