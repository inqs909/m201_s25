{
  "hash": "69ac111427cde828f45566ac650bb49f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Simple Linear Regression\"\ndate: 2/25/25\ndescription: |\n  Begins the discussion for linear regression.\n\nformat:\n  revealjs:\n    scrollable: true\n    theme: [default, styles.scss]\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: notes/chalkboard_1a.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n  - reveal-auto-agenda\neditor: source\n---\n\n\n\n\n\n\n\n# Modeling Relationships\n\n## Explaining Variation\n\n::: fragment\nThis is the process where we try to reduce the variation with the use of other variables.\n:::\n\n::: fragment\nCan be thought of as getting it less wrong when taking an educated guess.\n:::\n\n## Explaining Variation\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n\n## Explaining Variation with One Variable\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n\n\n# A Simple Model\n\n## Generated Model\n\n$$\nY \\sim DGP_1\n$$\n\n## A Simple Model\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n\n## A Simple Model\n\n$$\nY = \\_\\_\\_ + error\n$$\n\n## Notation\n\n$$\nY = \\ \\ \\ \\ \\ \\ \\ \\ \\ + \\varepsilon \n$$\n\n## The Simple Generated Model\n\n$$\nY \\sim \\mu + \\varepsilon\n$$\n\n$$\n\\varepsilon \\sim DGP_2\n$$\n\n::: fragment\n$DGP_2$ is not the same as the $DGP_1$, it is transformed due $\\beta_0$. Consider this the NULL $DGP$.\n:::\n\n## Observing Data\n\n$$\nY = \\beta_0 + \\varepsilon\n$$\n\n## Estimated Line\n\n$$\n\\hat Y=\\hat\\beta_0\n$$\n\n## Notation\n\n::: columns\n::: {.column width=\"50%\"}\n### Observed\n\n$$\nY = \\beta_0 + \\varepsilon\n$$\n:::\n\n::: {.column width=\"50%\"}\n### Estimated\n\n$$\n\\hat Y = \\hat \\beta_0\n$$\n:::\n:::\n\n# Modelling Data\n\n## Indexing Data\n\nThe data in a data set can be indexed by a number.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins[1,-c(1:2)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 6\n#>   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex    year\n#>            <dbl>         <dbl>             <int>       <int> <fct> <int>\n#> 1           39.1          18.7               181        3750 male   2007\n```\n\n\n:::\n:::\n\n\n\n\n::: fragment\nMaking the variable \"body_mass_g\" be represented by $Y$ and \"flipper_length_mm\" as $X$:\n\n$$\nY_1 = 3750 \\ \\ X_1=181\n$$\n:::\n\n## Indexing Data\n\n$$\nY_i, X_i\n$$\n\n## Data\n\nWith the data that we collect from a sample, we hypothesize how the data was generated.\n\n::: fragment\nUsing a simple model:\n\n$$\nY_i = \\beta_0 + \\varepsilon_i\n$$\n:::\n\n## Estimated Value\n\n$$\n\\hat Y_i = \\hat \\beta_0\n$$\n\n## Estimation \n\nTo estimate $\\hat \\beta_0$, we minimize the follow function:\n\n$$\n\\sum^n_{i=1} (Y_i-\\hat Y_i)^2\n$$\n\n::: fragment\nThis is known as the sum squared errors, SSE \n:::\n\n\n\n## Residuals\n\nThe residuals are known as the observed errors from the data in the model:\n\n$$\nr_i = Y_i - \\hat Y_i\n$$\n\n## Estimation in R\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Y ~ 1, data = DATA)\n```\n:::\n\n\n\n\n\n## Modeling Body Mass in Penguins\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(body_mass_g ~ 1, data = penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ 1, data = penguins)\n#> \n#> Coefficients:\n#> (Intercept)  \n#>        4207\n```\n\n\n:::\n:::\n\n\n\n\n\n# Linear Model\n\n## Linear Model\n\nThe goal of Statistics is to develop models the have a better explanation of the outcome $Y$.\n\n::: fragment\nIn particularly, reduce the sum of squared errors.\n:::\n\n::: fragment\nBy utilizing a bit more of information, $X$, we can increase the predicting capabilities of the model.\n:::\n\n::: fragment\nThus, the linear model is born.\n:::\n\n## Linear Model\n\n$$\nY = \\beta_0 + \\beta_1 X + \\varepsilon\n$$\n\n$$\n\\varepsilon \\sim DGP_3\n$$\n\n## Scatter Plot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(flipper_length_mm, body_mass_g)) + \n  geom_point() +\n  theme(axis.text.x = element_text(size = 24),\n                   axis.title.x = element_text(size = 30),\n                   plot.title = element_text(size = 48),\n                   strip.text = element_text(size = 20),\n                   legend.title = element_blank(),\n                   legend.text = element_text(size = 24))\n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n\n## Imposing a Line\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(penguins, aes(flipper_length_mm, body_mass_g)) + \n  geom_point() +\n  stat_smooth(method = \"lm\", se = F) +\n  theme(axis.text.x = element_text(size = 24),\n                   axis.title.x = element_text(size = 30),\n                   plot.title = element_text(size = 48),\n                   strip.text = element_text(size = 20),\n                   legend.title = element_blank(),\n                   legend.text = element_text(size = 24))\n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n\n## Modelling the Data\n\n$$\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\n$$\n\n## Linear Model\n\n$$\n\\hat Y_i = \\hat \\beta_0 + \\hat \\beta_1 X_i\n$$\n\n::: fragment\nGoal is to obtain numerical values for $\\hat \\beta_0$ and $\\hat \\beta_1$ that will minimize the SSE.\n:::\n\n## SSE\n\n$$\n\\sum^n_{i=1} (Y_i-\\hat Y_i)^2\n$$\n\n\n$$\n\\hat Y_i = \\hat \\beta_0 + \\hat \\beta_1 X_i\n$$\n\n## Fitting a Model in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Y ~ X, data = DATA)\n```\n:::\n\n\n\n\n## Example\n\n\nY: \"body_mass_g\"; X: \"flipper_length_mm\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(body_mass_g ~ flipper_length_mm, data = penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ flipper_length_mm, data = penguins)\n#> \n#> Coefficients:\n#>       (Intercept)  flipper_length_mm  \n#>          -5872.09              50.15\n```\n\n\n:::\n:::\n\n\n\n\n\n$$\n\\hat Y_i = -5872.09 + 50.15 X_i\n$$\n\n\n## Interpretation of $\\hat\\beta_0$\n\nThe intercept $\\hat \\beta_0$ can be interpreted as the base value when $X$ is set to 0.\n\n::: fragment\nSome times the intercept can be interpretable to real world scenarios.\n:::\n\n::: fragment\nOther times it cannot.\n:::\n\n## Interpreting Example\n\n$$\n\\hat Y_i = -5872.09 + 50.15 X_i\n$$\nWhen flipper length is 0 mm, the body mass is -5872 grams.\n\n## Interpretation of $\\hat \\beta_1$\n\nThe slope $\\hat \\beta_1$ indicates how will y change when x increases by 1 unit.\n\n::: fragment\nIt will demonstrate if there is, on average, a positive or negative relationship based on the sign provided.\n:::\n\n## Interpreting Example\n\n$$\n\\hat Y_i = -5872.09 + 50.15 X_i\n$$\n\nWhen flipper length increases by 1 mm, the body mass will increase by 50.15 grams.\n\n\n# Categorical Variables\n\n## Body Mass with Species\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npenguins |> \n  ggplot(aes(body_mass_g)) +\n    geom_boxplot() +\n    theme(axis.text.x = element_text(size = 24),\n          axis.title.x = element_text(size = 30),\n          plot.title = element_text(size = 48),\n          strip.text = element_text(size = 20),\n          legend.title = element_blank(),\n          legend.text = element_text(size = 24))\n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\n\n## Body Mass with Species\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npenguins |> \n  ggplot(aes(body_mass_g, fill = species)) +\n    geom_boxplot() +\n    theme(axis.text.x = element_text(size = 24),\n          axis.title.x = element_text(size = 30),\n          plot.title = element_text(size = 48),\n          strip.text = element_text(size = 20),\n          legend.title = element_blank(),\n          legend.text = element_text(size = 24))\n```\n\n::: {.cell-output-display}\n![](7_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n\n\n## Group Statistics\n\nWe can use statistics to explain a continuous variable by the categories.\n\n::: fragment\nCompute statistics for each group.\n:::\n\n::: fragment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_by_cat_stats(DATA, NUM, CAT)\n```\n:::\n\n\n\n:::\n\n\n## Compute Group Statistics\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_by_cat_stats(penguins, body_mass_g, species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 3 × 11\n#>   species     min   q25  mean median   q75   max    sd     var   iqr missing\n#>   <fct>     <int> <dbl> <dbl>  <dbl> <dbl> <int> <dbl>   <dbl> <dbl>   <int>\n#> 1 Adelie     2850 3362. 3706.   3700  4000  4775  459. 210332.  638.       0\n#> 2 Chinstrap  2700 3488. 3733.   3700  3950  4800  384. 147713.  462.       0\n#> 3 Gentoo     3950 4700  5092.   5050  5500  6300  501. 251478.  800        0\n```\n\n\n:::\n:::\n\n\n\n\n\n## Linear Models with Categorical Variables\n\nA line is normally used to model 2 continuous variables.\n\n::: fragment\nHowever, the predictor variable $X$ can be restricted to a set a variables that can symbolize categories.\n:::\n\n::: fragment\nA category will be used as a reference for a model.\n:::\n\n\n## Binary (Dummy) Variables\n\nBinary variables are variable that can only take on the value 0 or 1.\n\n$$\nD_i = \\left\\{\n\\begin{array}{cc}\n1 & Category\\\\\n0 & Other\n\\end{array}\n\\right.\n$$\n\n## Binary (Dummy) Variables\n\nTo fit a model with categorical variables, we must utilize dummy (binary) variables that indicate which category is being referenced. We use $C-1$ dummy variables where $C$ indicates the number of categories. When coded correctly, each category will be represented by a combination of dummy variables.\n\n## Example\n\nIf we have 4 categories, we will need 3 dummy variables:\n\n|         | Cat 1 | Cat 2 | Cat 3 | Cat 4 |\n|---------|-------|-------|-------|-------|\n| Dummy 1 | 1     | 0     | 0     | 0     |\n| Dummy 2 | 0     | 1     | 0     | 0     |\n| Dummy 2 | 0     | 0     | 1     | 0     |\n\n\n## Species Dummy Variables\n\n|         | Chinstrap | Gentoo | Adelie |\n|---------|-------|-------|-------|\n| $D_1$ | 1     | 0     | 0     |\n| $D_2$ | 0     | 1     | 0     |\n\n## Linear Model\n\n$$\n\\hat Y_i = \\hat \\beta_0 + \\hat\\beta_1 D_{1i} + \\hat\\beta_2 D_{2i}\n$$\n\n::: fragment\n$\\hat \\beta_1$ indicates how body mass changes from Adelie to Chinstrap.\n:::\n\n::: fragment\n$\\hat \\beta_2$ indicates how body mass changes from Adelie to Gentoo.\n:::\n\n::: fragment\n$\\hat \\beta_0$ represents the baseline level, in this case the body mass of Adelie.\n:::\n\n## Fitting a Model in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Y ~ X, data = DATA)\n```\n:::\n\n\n\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(body_mass_g ~ species, penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ species, data = penguins)\n#> \n#> Coefficients:\n#>      (Intercept)  speciesChinstrap     speciesGentoo  \n#>          3706.16             26.92           1386.27\n```\n\n\n:::\n:::\n\n\n\n\n$$\n\\hat Y_i = 3706 + 26.92 D_{1i} + 1386.27 D_{2i}\n$$\n\n## Finding the Adelie MASS\n\n$$\n\\hat Y_i = 3706 + 26.92 (0) + 1386.27 (0)\n$$\n\n## Finding the Chinstrap MASS\n\n$$\n\\hat Y_i = 3706 + 26.92 (1) + 1386.27 (0)\n$$\n\n## Finding the Gentoo MASS\n\n$$\n\\hat Y_i = 3706 + 26.92 (0) + 1386.27 (1)\n$$\n\n## Intepreting $\\hat \\beta_1$\n\nOn average, Chinstrap has a larger mass than Adelie by about 26.92 grams.\n\n## Intepreting $\\hat \\beta_2$\n\nOn average, Gentoo has a larger mass than Adelie by about 1386.27 grams.\n\n# Strength and Correlation\n\n## Correlation\n\nCorrelation is a statistics that can be used to describe the strength of the relationship between 2 continuous variables.\n\n::: fragment\n$$\nr = \\frac{1}{n-1}\\sum^n_{i=1}\\frac{x_i - \\bar x}{s_x}\\frac{y_i - \\bar y}{s_y}\n$$\n\n-   $\\bar x$, $\\bar y$: sample means\n-   $s_x$, $s_y$: sample standard deviations\n\n:::\n\n::: fragment\n$$\n-1 \\leq r \\leq 1\n$$\n:::\n\n\n## Correlations\n\n![From IMS 2e](https://openintro-ims.netlify.app/model-slr_files/figure-html/fig-posNegCorPlots-1.png)\n\n## Coefficient of Determination\n\nThe coefficient of determination evaluates the strength between an outcome $Y$ and the linear model, which includes $X$.\n\n::: fragment\n$$\nR^2 = r^2\n$$\n:::\n\n::: fragment\n$$\n0 \\leq R^2 \\leq 1\n$$\n:::\n\n::: fragment\nThe coefficient of determination measures the total variation explained by the linear model. The closer to 1, the better the linear model.\n:::\n\n## Correlation in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(DATA$Y, DATA$X)\n```\n:::\n\n\n\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(penguins$body_mass_g, penguins$flipper_length_mm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.8729789\n```\n\n\n:::\n:::\n\n\n\n\n## Coefficient of Determination in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxlm <- lm(Y ~ X, data = DATA)\nr2(xlm)\n```\n:::\n\n\n\n\n\n## Example\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxlm <- lm(body_mass_g ~ species, penguins)\nr2(xlm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.6744887\n```\n\n\n:::\n:::\n",
    "supporting": [
      "7_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}