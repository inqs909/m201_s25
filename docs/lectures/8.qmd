---
title: "Randomization Tests"
format:
  revealjs:
    width: 1200
    df-print: paged
    scrollable: true
    theme: [default, styles.scss]
    navigation-mode: vertical
    controls-layout: bottom-right
    controls-tutorial: true
    incremental: false 
    chalkboard:
      theme: whiteboard
      chalk-width: 4
knitr:
  opts_chunk: 
    echo: true
    eval: true
    message: false
    code-fold: true
    warnings: false
    comment: "#>" 
    
revealjs-plugins:
  - pointer
  - verticator
  
filters: 
  - reveal-header
  - code-fullscreen
  - reveal-auto-agenda
editor: source
---

```{r}
#| include: false
library(MASS)
library(tidyverse)
library(csucistats)
library(waffle)
library(patchwork)

theme_set(theme_bw() + 
            theme(
              axis.text.x = element_text(size = 24),
              axis.title = element_text(size = 30),
              plot.title = element_text(size = 48),
              strip.text = element_text(size = 20),
              legend.title = element_blank(),
              legend.text = element_text(size = 24)))

```

# Sampling Distribution

## Sampling Distribution

Sampling Distribution is the idea that the statistics that you generate (slopes and intercepts) have their own data generation process.

::: fragment
In other words, the numerical values you obtain from the `lm` and `glm` function can be different if we got a different data set.
:::

::: fragment
Some values will be more common than others. Because of this, they have their own data generating process, like the outcome of interest has it's own data generating process.
:::

## Modelling the Data

$$
Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i
$$ 

- $Y_i$: Outcome data 
- $X_i$: Predictor data 
- $\beta_0, \beta_1$: parameters 
- $\varepsilon_i$: error term

## Error Term

$$
\varepsilon_i \sim DGP
$$

::: notes
-   The error terms forces the outcome variable to be different from the mathematical model.
-   The numbers being generated are random and cannot be predicted.
:::

## Randomness Effect

```{r}
#| echo: false
ggplot(tibble(x = rnorm(1000), y = rnorm(1000)), aes(x,y)) +
  geom_point() +
  theme_void()
```

# Simulating Unicorns

## Simulating Unicorns

To better understand the variation in statistics, let's simulate a data set of unicorn characteristics to visualize and understand the variation.

::: fragment
We will simulate a data set using then `unicorns` function and only need to specify how many unicorns you want to simulate.
:::

## Simulating Unicorn Data

```{r}
#| code-fold: show
unicorns(10)
```

## Unicorn Data Variables

```{r}
#| code-fold: show

names(unicorns(10))
```

We will only look at `Magical_Score` and `Nature_Score`.

## Magical and Nature Score

$$
Magical =  3423 + 8 \times Nature + \varepsilon
$$ 

$$
\varepsilon \sim N(0, 3.24)
$$

## Simulating $N(0, 3.24)$

```{r}
#| code-fold: show
rnorm(1, 0, 1.8)
```

## Collecting

```{r}
unicorns(10) |> select(Nature_Score, Magical_Score)
```

## DGP of Magical Score 1

```{r}
ggplot(unicorns(500), aes(Magical_Score)) +
  geom_density()
```

## DGP of Magical Score 2

```{r}
ggplot(unicorns(500), aes(Magical_Score)) +
  geom_density()
```

## Estimating $\beta_1$ via `lm`

```{r}
u1 <- unicorns(500)
lm(Magical_Score ~ Nature_Score, u1)
```

## Collecting a new sample

```{r}
u2 <- unicorns(500)
lm(Magical_Score ~ Nature_Score, u2)
```

## Collecting a new sample

```{r}
u3 <- unicorns(500)
lm(Magical_Score ~ Nature_Score, u3)
```

## Collecting a new sample

```{r}
u4 <- unicorns(500)
lm(Magical_Score ~ Nature_Score, u4)
```

## Collecting 1000 Samples

```{r}
betas <- replicate(1000,
                   b(Magical_Score ~ Nature_Score, 1, unicorns(500)))

betas
```

## Distributions of $\hat \beta_1$

```{r}
ggplot(tibble(x = betas), aes(x = x)) +
  geom_density()
```

# Hypothesis Testing

## Inference

In the real world, we do not know how the model is generated; therefore, the parameters that are being estimated are unknown.

::: fragment
We use statistics to determine what is our best guess of what the true parameter is.
:::

::: fragment
We can use processes known as inferential procedures to determine which values of the parameter it cannot be. This is known as inference.
:::

## Hypothesis Tests

Hypothesis tests are used to test whether claims are valid or not. This is conducted by collecting data, setting the **Null** and **Alternative** Hypothesis.

## Null Hypothesis $H_0$

The null hypothesis is the claim that is initially believed to be true. For the most part, it is always equal to the hypothesized value.

## Alternative Hypothesis $H_a$

The alternative hypothesis contradicts the null hypothesis.

## Example of Null and Alternative Hypothesis

We want to see if $\mu$ (the true value) is different from $\mu_0$ (a number we want to test)

| Null Hypothesis    | Alternative Hypothesis |
|--------------------|------------------------|
| $H_0: \mu=\mu_0$   | $H_a: \mu\ne\mu_0$     |
| $H_0: \mu\le\mu_0$ | $H_a: \mu>\mu_0$       |
| $H_0: \mu\ge\mu_0$ | $H_0: \mu<\mu_0$       |

## Hypothesis Test

The idea of hypothesis testing is to generate the sampling distribution of a statistic assuming the null hypothesis is true.

::: fragment
Compute the statistic from your data.
:::

::: fragment
Afterwards, see where your statistic lies in comparison of your null sampling distribution.
:::

## Comparison of Null Distribution

If your statistic lies near the mounds, it is believed that your data came from the null distribution.

If your statistic is more in the tail regions, it is believed that your data **did not** come from your null distribution.

# Comparing Proportions

## Motivation

The `bacteria` data set contians information on whether bacteria (`y`: y or n) is present after utilizing treatments (`ap`: **a**ctive or **p**lacebo).

::: fragment
We are interesting in determine the proportion of having bacteria present is different for those taking an "active" or "placebo".
:::

## Crosstabulation

```{r}
cat_stats(bacteria$ap, bacteria$y)
```



## Comparing Proportions

We are interesting in determining if different groups see different proportions of a binary outcome.

We compute the proportions of observing the binary outcome in Group 1 and Group 2 and see if they are fundamentally different from each other.

## 2 by 2 Cross Tabulations

|         |           |           |
|---------|-----------|-----------|
| Groups  | Outcome 1 | Outcome 2 |
| Group 1 | $p_{11}$  | $p_{21}$  |
| Group 2 | $p_{12}$  | $p_{22}$  |


::: fragment
We want to compare $p_{11}$ and $p_{12}$, to determine if the probability of outcome 1 are the same for both groups.

:::

## Test Statistic

We can use both $p_{11}$ and $p_{12}$ to determine if there is a fundamental difference.

::: fragment
However, it will be more beneficial to utilize one statistic to contruct the sampling distribution.
:::

::: fragment
$$
T =  p_{11} - p_{12}
$$
:::

## Obtain Proportion in R

```{r}
#| echo: true
#| eval: false

props(DATA$GROUP, DATA$OUTCOME, VAL)
```

## Obtain Difference in R

```{r}
#| echo: true
#| eval: false

props(DATA$GROUP, DATA$OUTCOME, VAL, diff = TRUE)
```

## Bacteria Example

```{r}
props(bacteria$ap, bacteria$y, "y")
```

## Bacteria Example

```{r}
props(bacteria$ap, bacteria$y, "y", TRUE)
```

## Hypothesis Test

Is 12.5% of a difference large enough to indicate that an active drug is effective against the bacteria, or seeing this can be due to random chance.


## Hypotheis Test

We will test the following hypothesis:

$$
H_0:\ p_1-p_2 = 0
$$

$$
H_a:\ p_1 - p_2 \neq 0
$$

## Hypothesis Test

In words:

$H_0$: The variables bacteria presence and active drug treatment are independent of each other.

$H_a$: The variables bacteria presence and active drug treatment are dependent of each other.


# Randomization Tests

## Visualizing 

```{r}
#| eval: false
ab <- cat_stats(bacteria$y[bacteria$ap == "a"], pie = TRUE)
abp <- ggplot(ab, aes(fill = Category, values = n)) +
  geom_waffle(make_proportional = TRUE) + 
  ggtitle("Active Treatment") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))

pb <- cat_stats(bacteria$y[bacteria$ap == "p"], pie = TRUE)
pbp <- ggplot(pb, aes(fill = Category, values = n)) +
  geom_waffle(make_proportional = TRUE) +
  ggtitle("Placebo") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))



abp + pbp + plot_layout(guides = 'collect')


```


## Randomization Tests

The idea of a randomization test is that each observed outcome variable was dictated by a mathematical model.

::: fragment
Therefore, a randomization is most interested to determine if the mathematical model exist or completely random. 
:::

::: fragment
This is equivalent to saying the there is not pattern in the data. IE, independent variables.
:::

## Randomization Tests

$H_0$: The outcome and predictor variables are **independent** of each other.

$H_a$: The outcome and predictor variables are **dependent** of each other.

## Randomziation 1


```{r}
#| eval: false
ab <- cat_stats(shuffle(bacteria$y)[bacteria$ap == "a"], pie = TRUE)
abp <- ggplot(ab, aes(fill = Category, values = n)) +
  geom_waffle(make_proportional = TRUE) + 
  ggtitle("Active Treatment") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))

pb <- cat_stats(shuffle(bacteria$y)[bacteria$ap == "p"], pie = TRUE)
pbp <- ggplot(pb, aes(fill = Category, values = n)) +
  geom_waffle(make_proportional = TRUE) +
  ggtitle("Placebo") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))



abp + pbp + plot_layout(guides = 'collect')
```


## Randomziation 2


```{r}
#| eval: false
ab <- cat_stats(shuffle(bacteria$y)[bacteria$ap == "a"], pie = TRUE)
abp <- ggplot(ab, aes(fill = Category, values = n)) +
  geom_waffle(make_proportional = TRUE) + 
  ggtitle("Active Treatment") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))

pb <- cat_stats(shuffle(bacteria$y)[bacteria$ap == "p"], pie = TRUE)
pbp <- ggplot(pb, aes(fill = Category, values = n)) +
  geom_waffle(make_proportional = TRUE) +
  ggtitle("Placebo") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))



abp + pbp + plot_layout(guides = 'collect')
```


## Randomziation 3


```{r}
#| eval: false
ab <- cat_stats(shuffle(bacteria$y)[bacteria$ap == "a"], pie = TRUE)
abp <- ggplot(ab, aes(fill = Category, values = n)) +
  geom_waffle(make_proportional = TRUE) + 
  ggtitle("Active Treatment") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))

pb <- cat_stats(shuffle(bacteria$y)[bacteria$ap == "p"], pie = TRUE)
pbp <- ggplot(pb, aes(fill = Category, values = n)) +
  geom_waffle(make_proportional = TRUE) +
  ggtitle("Placebo") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))



abp + pbp + plot_layout(guides = 'collect')
```


## Randomziation 4


```{r}
#| eval: false
ab <- cat_stats(shuffle(bacteria$y)[bacteria$ap == "a"], pie = TRUE)
abp <- ggplot(ab, aes(fill = Category, values = n)) +
  geom_waffle(make_proportional = TRUE) + 
  ggtitle("Active Treatment") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))

pb <- cat_stats(shuffle(bacteria$y)[bacteria$ap == "p"], pie = TRUE)
pbp <- ggplot(pb, aes(fill = Category, values = n)) +
  geom_waffle(make_proportional = TRUE) +
  ggtitle("Placebo") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5))



abp + pbp + plot_layout(guides = 'collect')
```


## Randomization Test

The act of randomizing the outcome to a set of predictor variables allow you to construct the sampling of distribution of the null hypothesis.

::: fragment
$H_0$: The variables bacteria presence and active drug treatment are independent of each other. $p_{active}-p_{placebo} = 0$

$H_a$: The variables bacteria presence and active drug treatment are dependent of each other. $p_{active}-p_{placebo} \neq 0$
:::

## Simulating $H_0$

We are interested in simulating the distribution for $p_{active}-p_{placebo}$. We do this by randomly assigning the observed outcomes to the predictor variable. Then, we compute the difference in proportions using the `props` function. Afterwards, we store the value and repeat the process again.

::: fragment
Lastly, we compare where the data statistic compared to our simulated distribution.
:::



## Shuffling Data

The `shuffle` function will mix up a variable in R:


```{r}
#| code-fold: show
#| eval: false

shuffle(VECTOR)
```


## Shuffle Data

```{r}
#| echo: true
#| code-fold: show
bacteria$y
```


```{r}
#| echo: true
#| code-fold: show

shuffle(bacteria$y)
```


## Computing Proportions

```{r}
#| code-fold: show

props(bacteria$ap, shuffle(bacteria$y), "y", T)
```


## Repeat Process

```{r}
#| code-fold: show

props(bacteria$ap, shuffle(bacteria$y), "y", T)
props(bacteria$ap, shuffle(bacteria$y), "y", T)
props(bacteria$ap, shuffle(bacteria$y), "y", T)
props(bacteria$ap, shuffle(bacteria$y), "y", T)
props(bacteria$ap, shuffle(bacteria$y), "y", T)
props(bacteria$ap, shuffle(bacteria$y), "y", T)
props(bacteria$ap, shuffle(bacteria$y), "y", T)

```

## The `replicate` Function

The `replicate` function will execute a task multiple times and store the values in a vector.

```{r}
#| code-fold: show
#| eval: false

replicate(N, FUN)
```


- N: number of simulations
- FUN: the command to be repeated


## Repeat 1000 times

```{r}
#| code-fold: show

sim_stats <- replicate(1000, props(bacteria$ap, shuffle(bacteria$y), "y", T))
sim_stats
```

## Visualize Data

```{r}

ggplot(data.frame(x = sim_stats), aes(x)) + geom_density()
```

## Compute Data Propoortion


```{r}
#| code-fold: show
test_stat <- props(bacteria$ap, bacteria$y, "y", T)
test_stat
```


## Comparison

```{r}
#| code-fold: show

ggplot(data.frame(x = sim_stats), aes(x)) + 
  geom_density() +
  geom_vline(xintercept = test_stat)
```

# P-Value

## P-Value

The p-value determines the probability of observing our data statistic, given that the null hypothesis is true.

::: fragment
When the p-value is large, we believe there is a high probability that the null hypothesis is true.
:::

::: fragment
When the p-value is small, we believe that it is unlikely the the null hypothesis is true. We believe that the alternative may be a better model.
:::

## 2-Sided P-Value

Due to randomness, there is a possibility of observing the same magnitude of $p_{active}-p_{placebo}$, but in the opposite direction; therefore, we must look at both sides.

## Visually 2-Sided P-Value

```{r}
#| echo: true
ggplot(data.frame(x = sim_stats), aes(x)) + 
  geom_density() +
  geom_vline(xintercept = c(-1,1) *test_stat)
```

## Computing the p-value

We will count how many simulated $p_{active}-p_{placebo}$'s are more extreme than our test statistic and divided by the number of simulations plus one.

## Computing the p-value

$$
p = \frac{m +1}{N + 1}
$$

-   $m$: number of more extreme values than our test statistic
-   $N$: number of simulations


## Computing the P-Value

```{r}
#| code-fold: show
#| eval: false

(sum(abs(SIM_VECTOR) > abs(TEST_STAT)) + 1) / (N + 1)
```


## Computing P-value

```{r}
sum(abs(sim_stats) > abs(test_stat)) / 1001
```
# Process

## Identify your Variables

-   What is your predictor variable?
-   What is your outcome variable?


## Create your Hypothesis

Choose a hypothesis that is appropriate for your model.

## Compute a test statistic for the data

Identify what is you want to compute and compare.

## Generate a null distribution.

Simulate the potential null distribution using the `shuffle` and `replicate` function.

## Compute the p-value

Use the probability formula to determine the likelihood of observing your test statistic given that the null hypothesis is true.